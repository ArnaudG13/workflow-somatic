#================================================================#
#                      Python Import
#================================================================#


import os
import re
import subprocess
import hashlib
import pandas as pd
from functools import partial


#================================================================#
#                      Shell Functions
#================================================================#

# Define functions to be used in shell portions
shell.prefix("""
PROGNAME=$(basename $0)

function error_exit
{{
#	----------------------------------------------------------------
#	Function for exit due to fatal program error
#		Accepts 1 argument:
#			string containing descriptive error message
#	----------------------------------------------------------------
    echo "${{PROGNAME}}: ${{1:-"Unknown Error"}}" 1>&2
    exit 1
}}
""")

#================================================================#
#                    Variables from config files
#================================================================#
#Check genome_dir
if not "genome_dir" in config["genome"].keys() :
    sys.exit("Missing parameters genome_dir")
else :
    if not os.path.exists(config["genome"]["genome_dir"]) :
        sys.exit("%s directory does not exist"%config["genome"]["genome_dir"])
    else :
        genome_dir = config["genome"]["genome_dir"]

#Check base_dir
if not "base" in config["dir"].keys() :
    sys.exit("Missing parameters base")
else :
    if not os.path.exists(config["dir"]["base"]) :
        sys.exit("%s directory does not exist"%config["dir"]["base"])
    base_dir = config["dir"]["base"].rstrip('/')
    output_dir = base_dir
    print("Base dir : %s"%base_dir)
    print("output dir : %s"%output_dir)

#Check fastq dir
if not "fastq_dir" in config["dir"].keys() :
    sys.exit("Missing parameters fastq_fir")
else :
    if not os.path.exists(config["dir"]["fastq_dir"]) :
        sys.exit("%s does not exist"%config["dir"]["fastq_dir"])
    else :
        fastq_dir=config["dir"]["fastq_dir"].rstrip('/')
    print("Fastq dir : %s"%config["dir"]["fastq_dir"])

#Check prior file jsm
if not "prior_file" in config["jsm"].keys() :
    sys.exit("prior file jsm not found")
else :
    if not os.path.exists(config["jsm"]["prior_file"]) :
        sys.exit("prior file jsm not found")

#Check init file file jsm
if not "init_file" in config["jsm"].keys() :
    sys.exit("init file jsm not found")
else :
    if not os.path.exists(config["jsm"]["init_file"]) :
        sys.exit("init file jsm not found")

#Check conda env file
if not os.path.exists(config["env1"]) :
    sys.exit("Missing env yaml file")
else:
    env_file=config["env1"]

#Check conda env file 2
if not os.path.exists(config["env2"]) :
    sys.exit("Missing env2 yaml file")
else:
    env_file2=config["env2"]

#Check conda env file 2
if not os.path.exists(config["env3"]) :
    sys.exit("Missing env3 yaml file")
else:
    env_file3=config["env3"]

#Check conda env file sv
if not os.path.exists(config["env_file_sv"]) :
    sys.exit("Missing env file sv yaml file")
else:
    env_file_sv=config["env_file_sv"]

#Check conda env gatk file
if not os.path.exists(config["env_file_gatk"]) :
    sys.exit("Missing env gatk yaml file")
else:
    env_file_gatk=config["env_file_gatk"]

#Check conda env file optitype
if not os.path.exists(config["env_optitype"]) :
    hla_typing = False
else:
    env_file_optitype=config["env_optitype"]

#Check mapping tool
if not "mapping" in config["tools"].keys() :
    sys.exit("Missing parameters mapping")
else :
    print("Mapping with : %s"%config["tools"]["mapping"])

#Check SE or PE
if not "paired" in config["tools"].keys() :
    sys.exit("Missing parameters paired")
else :
    if config["tools"]["paired"] == "1" :
        paired=True
    else:
        paired=False
    print("Paired reads : %s"%config["tools"]["paired"])

#Check ref file
if not "fasta_file" in config["genome"].keys() :
    sys.exit("Missing parameters fasta_file")
else :
    if not os.path.exists(config["genome"]["fasta_file"]) :
        sys.exit("%s does not exist"%config["genome"]["fasta_file"])
    print("Reference : %s"%config["genome"]["fasta_file"])

#Check ref dict file
if not "dict_file" in config["genome"].keys() :
    sys.exit("Missing parameters dict_file")
else :
    if not os.path.exists(config["genome"]["dict_file"]) :
        sys.exit("%s does not exist"%config["genome"]["dict_file"])
    print("Reference : %s"%config["genome"]["dict_file"])

#Check chrLength file
if not "chrLength_file" in config["genome"].keys() :
    sys.exit("Missing parameters chrLength_file")
else :
    if not os.path.exists(config["genome"]["chrLength_file"]) :
        sys.exit("%s does not exist"%config["genome"]["chrLength_file"])
    print("Reference : %s"%config["genome"]["chrLength_file"])

#Check hla_ref
if not "hla_ref" in config["genome"].keys() :
    hla_typing = False
else :
    if not os.path.exists(config["genome"]["hla_ref"]) :
        sys.exit("%s does not exist"%config["genome"]["hla_ref"])
    print("HLA Reference : %s"%config["genome"]["hla_ref"])

#Check target bed file
if not "design" in config["metadata"].keys() :
    sys.exit("Missing parameters design")
else :
    if not os.path.exists(config["metadata"]["design"]) :
        sys.exit("%s does not exist"%config["metadata"]["design"])
    print("Region Bed file : %s"%config["metadata"]["design"])

#Check target gz and tbi for StrelkaSomatic
if "Strelka" in config["tools"]["snv_calling_somatic"] or "Strelka" in config["tools"]["indel_calling_somatic"] :
    if not os.path.exists(config["metadata"]["design"]+".gz") or not os.path.exists(config["metadata"]["design"]+".gz.tbi") :
        sys.exit("Please index design bed file with bgzip and tabix")

#Check microsat file
if not "microsat" in config["metadata"].keys() :
    sys.exit("Missing parameters microsat")
else :
    if not os.path.exists(config["metadata"]["microsat"]) :
        sys.exit("%s does not exist"%config["metadata"]["microsat"])
    print("Microsat file : %s"%config["metadata"]["microsat"])

#Check analysis sheet
if not "analysis_sheet" in config["metadata"].keys() :
    sys.exit("Missing parameters analysis_sheet")
else :
    if not os.path.exists(config["metadata"]["analysis_sheet"]) :
        sys.exit("%s does not exist"%config["metadata"]["analysis_sheet"])
    print("Analysis sheet : %s"%config["metadata"]["analysis_sheet"])

#Check date
if not "date" in config["metadata"].keys() :
    sys.exit("Missing parameters date")

#Check center name
if not "center" in config["metadata"].keys() :
    sys.exit("Missing parameters center")

#Check platform name
if not "platform" in config["metadata"].keys() :
    sys.exit("Missing parameters platform")

if not "uniq" in config["tools"].keys() :
    sys.exit("Missing parameters uniq")
else :
    if config["tools"]["uniq"] == "1" :
        uniq=True
        tag_process_uniq = ".uniq."
    else:
        uniq=False
        tag_process_uniq = ""

if not "sv_calling" in config["tools"].keys() :
    sys.exit("Missing parameters sv_calling")
else :
    if config["tools"]["sv_calling"] == "Delly" :
        uniq=False
        tag_process_uniq = "."
    else:
        if config["tools"]["uniq"] == "1" :
            uniq=True
            tag_process_uniq = ".uniq."
        else :
            uniq=False
            tag_process_uniq = "."

params_trim_crop="250"

if not "ffpe" in config["tools"].keys() :
    sys.exit("Missing parameters FFPE")
else :
    if config["tools"]["ffpe"] == "1" and config["tools"]["sv_calling"] == "Delly" :
        params_trim_crop="100"

if not "dedup" in config["tools"].keys() :
    sys.exit("Missing parameters dedup")
else :
    if config["tools"]["dedup"] == "1" :
        dedup=True
        tag_process_dedup = ".dedup."
        dedup_option_vardict = "--dedup"
        dedup_option_pisces = "--filterduplicates true"
        dedup_option_platypus = "--filterDuplicates=1"     
    else:
        dedup=False
        tag_process_dedup = "."
        dedup_option_vardict = ""
        dedup_option_pisces = ""
        dedup_option_platypus = "--filterDuplicates=0" 

if not "trimming" in config["tools"].keys() :
    sys.exit("Missing parameters trimming")
else :
    if config["tools"]["trimming"] == "1" :
        trimming=True
    else:
        trimming=False


#process molecular barcode or not
if not "molecular_barcode" in config["tools"].keys():
    sys.exit("Missing parameters molecular barcode")
else :
    if config["tools"]["molecular_barcode"] == "1" :
        molecular_barcode = True
        tag_process_mb = ".LocatIt."
    else :
        molecular_barcode = False
        tag_process_mb = "."

#run HLA-typing or not
#process molecular barcode or not
if not "hla_typing" in config["tools"].keys():
    hla_typing = False
else :
    if config["tools"]["hla_typing"] == "1" :
        hla_typing = True
    else :
        hla_typing = False

#Check app name (Target, Target-HS, Target-HSX or Exome)
if not "application" in config["metadata"].keys() :
    sys.exit("Missing parameters application")
else :
    processing = tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall"

if not "version" in config["genome"].keys() :
    sys.exit("Missing parameters genome version")
else :
    if config["genome"]["version"] == "hg19" :
        #Check annovar db
        if not "hg19_db" in config["annovar"].keys() :
            sys.exit("Annovar db not found")
        else :
            if not os.path.exists(config["annovar"]["hg19_db"]) :
                sys.exit("Annovar db not found")
            else :
                annovar_db = config["annovar"]["hg19_db"]
                base_used_germline="refGene,exac03nontcga,kaviar_20150923,hrcr1,esp6500siv2_all,1000g2015aug_all,snp138NonFlagged,snp129,cosmic70,clinvar_20180603,dbnsfp33a,dbscsnv11,intervar_20180118"
                base_used_somatic="refGene,exac03nontcga,kaviar_20150923,hrcr1,esp6500siv2_all,1000g2015aug_all,snp138NonFlagged,snp129,cosmic70,clinvar_20180603,dbnsfp33a"
    elif config["genome"]["version"] == "hg38":
        if not "hg38_db" in config["annovar"].keys() :
            sys.exit("Annovar db not found")
        else :
            if not os.path.exists(config["annovar"]["hg38_db"]) :
                sys.exit("Annovar db not found")
            else :
                annovar_db = config["annovar"]["hg38_db"]
                base_used_germline="refGene,exac03nontcga,kaviar_20150923,hrcr1,esp6500siv2_all,1000g2015aug_all,avsnp150,gnomad30_genome,cosmic95_coding,clinvar_20210501,dbnsfp42c,dbscsnv11,intervar_20180118"
                base_used_somatic="refGene,exac03nontcga,kaviar_20150923,hrcr1,esp6500siv2_all,1000g2015aug_all,avsnp150,gnomad30_genome,cosmic95_coding,clinvar_20210501,dbnsfp42c"
    else :
        sys.exit("wrong parameters genome version, only hg19 or hg38 are accepted")

#Check know site file
if not "known_site" in config["genome"].keys() :
    sys.exit("Missing parameters known_site")
else :
    if not os.path.exists(config["genome"]["known_site"]) :
        sys.exit("%s does not exist"%config["genome"]["known_site"])
    print("Known site : %s"%config["genome"]["known_site"])

#Check cosmic file
if not "cosmic" in config["genome"].keys() :
    sys.exit("Missing parameters cosmic")
else :
    if not os.path.exists(config["genome"]["cosmic"]) :
        sys.exit("%s does not exist"%config["genome"]["cosmic"])
    print("cosmic db : %s"%config["genome"]["cosmic"])

#Check map file
if not "map_file" in config["genome"].keys() :
    sys.exit("Missing parameters map_file")
else :
    if not os.path.exists(config["genome"]["map_file"]) :
        sys.exit("%s does not exist"%config["genome"]["map_file"])
    print("map_file : %s"%config["genome"]["map_file"])

#Check exac common file
if not "exac_common" in config["genome"].keys() :
    sys.exit("Missing parameters exac_common")
else :
    if not os.path.exists(config["genome"]["exac_common"]) :
        sys.exit("%s does not exist"%config["genome"]["exac_common"])
    print("exac_common : %s"%config["genome"]["exac_common"])

#Check gnomad_af_only file
if not "gnomad_af_only" in config["genome"].keys() :
    sys.exit("Missing parameters gnomad_af_only")
else :
    if not os.path.exists(config["genome"]["gnomad_af_only"]) :
        sys.exit("%s does not exist"%config["genome"]["gnomad_af_only"])
    print("gnomad_af_only : %s"%config["genome"]["gnomad_af_only"])

#Check pon file
if config["mutect2"]["create_pon"] == "0" :
    if not "pon" in config["mutect2"].keys() :
        sys.exit("Missing parameters pon")
    else :
        if not os.path.exists(config["mutect2"]["pon"]) :
            sys.exit("%s does not exist"%config["mutect2"]["pon"])
        print("pon : %s"%config["mutect2"]["pon"])

#Check gc file
if not "gc_file" in config["genome"].keys() :
    sys.exit("Missing parameters gc_file")
else :
    if not os.path.exists(config["genome"]["gc_file"]) :
        sys.exit("%s does not exist"%config["genome"]["gc_file"])
    print("gc_file : %s"%config["genome"]["gc_file"])

#Check iAnnotSV files
if not os.path.exists(config["iAnnotSV"]["ref_file"]) :
    sys.exit("Missing iAnnot rf file")

if not os.path.exists(config["iAnnotSV"]["canonical_txt"]) :
    sys.exit("Missing iAnnot canonical_txt file")

if not os.path.exists(config["iAnnotSV"]["uniprot"]) :
    sys.exit("Missing iAnnot uniprot file")

if not os.path.exists(config["iAnnotSV"]["repeat_region"]) :
    sys.exit("Missing iAnnot repeat region file")

if not os.path.exists(config["iAnnotSV"]["dgv"]) :
    sys.exit("Missing iAnnot dgv file")

if not os.path.exists(config["iAnnotSV"]["cancer_census"]) :
    sys.exit("Missing iAnnot census region file")

if not os.path.exists(config["iAnnotSV"]["cosmic_fusion_count"]) :
    sys.exit("Missing iAnnot fusion count region file")

if not os.path.exists(config["iAnnotSV"]["cosmic_fusion_count"]) :
    sys.exit("Missing iAnnot fusion count region file")

if not os.path.exists(config["iAnnotSV"]["all_canonical_txt"]) :
    sys.exit("Missing iAnnot all canonical_txt")

if not os.path.exists(config["iAnnotSV"]["region_to_exclude"]) :
    sys.exit("Missing iAnnot region_to_exclude")

#GERMLINE Variant Caller used for the analysis
if config["tools"]["snv_calling_germline"] == "All" :
    vc_list_snv_germline = ['FreeBayes', 'HaplotypeCaller','Pisces','Platypus','Strelka','VarScan2']
else :
    vc_list_snv_germline = config["tools"]["snv_calling_germline"]
    
if config["tools"]["indel_calling_germline"] == "All" :
    vc_list_indel_germline = ['FreeBayes', 'HaplotypeCaller', 'pindel', 'Pisces', 'Platypus', 'Scalpel', 'Strelka', 'Strelka', 'VarScan2']
else :
    vc_list_indel_germline = config["tools"]["indel_calling_germline"]

#SOMATIC Variant Caller used for the analysis
if config["tools"]["snv_calling_somatic"] == "All" :
    vc_list_snv_somatic = ['FreeBayes', 'Lancet', 'LoFreq', 'Muse', 'Mutect', 'Mutect2', 'Seurat', 'Shimmer', 'SomaticSniper', 'Strelka', 'VarDict', 'VarScan2', 'Virmid']
else :
    vc_list_snv_somatic = config["tools"]["snv_calling_somatic"]
    
if config["tools"]["indel_calling_somatic"] == "All" :
    vc_list_indel_somatic = ['FreeBayes', 'Lancet', 'LoFreq', 'Mutect2', 'pindel', 'Seurat', 'Scalpel', 'Strelka', 'VarDict', 'VarScan2']
else :
    vc_list_indel_somatic = config["tools"]["indel_calling_somatic"]

if not "n_concordant_somatic_snv" in config["tools"].keys() :
    n_concordant_somatic_snv = 4
else :
    n_concordant_somatic_snv = config["tools"]["n_concordant_somatic_snv"]

if not "n_concordant_somatic_indel" in config["tools"].keys() :
    n_concordant_somatic_indel = 4
else :
    n_concordant_somatic_indel = config["tools"]["n_concordant_somatic_indel"]


if not "n_concordant_germline_snv" in config["tools"].keys() :
    n_concordant_germline_snv = 3
else :
    n_concordant_germline_snv = config["tools"]["n_concordant_germline_snv"]


if not "n_concordant_germline_indel" in config["tools"].keys() :
    n_concordant_germline_indel = 4
else :
    n_concordant_germline_indel = config["tools"]["n_concordant_germline_indel"]

if not "create_pon" in config["mutect2"].keys() :
    create_pon = False
else :
    if config["mutect2"]["create_pon"] == "1" :
        create_pon = True
    else :
        create_pon = False

if not "mutect2_tumor_only" in config["tools"].keys() :
    mutect2_tumor_only = False
else :
    if config["tools"]["mutect2_tumor_only"] == "1" :
        mutect2_tumor_only = True
    else :
        mutect2_tumor_only = False

if not "run" in config["GATK4_CNA"].keys() :
    run_gatk4_cna = False
else :
    if config["GATK4_CNA"]["run"] == "1" :
        run_gatk4_cna = True
    else :
        run_gatk4_cna = False

if not "create_pon_cna" in config["GATK4_CNA"].keys() :
    create_pon_cna = False
else :
    if config["GATK4_CNA"]["create_pon_cna"] == "1" :
        create_pon_cna = True
    else :
        create_pon_cna = False

if not "run" in config["PureCN"].keys() :
    run_purecn = False
else :
    if config["PureCN"]["run"] == "1" :
        run_purecn = True
    else :
        run_purecn = False

if not "create_normal_db" in config["PureCN"].keys() :
    create_normal_db = False
else :
    if config["PureCN"]["create_normal_db"] == "1" :
        create_normal_db = True
    else :
        create_normal_db = False

#Check normal_db file
if config["PureCN"]["create_normal_db"] == "0" :
    if not "normal_db" in config["PureCN"].keys() :
        sys.exit("Missing parameters normal_db")
    else :
        if not os.path.exists(config["PureCN"]["normal_db"]) :
            sys.exit("%s does not exist"%config["PureCN"]["normal_db"])
        print("pon : %s"%config["PureCN"]["normal_db"])

#Check mapping_bias file
if config["PureCN"]["create_normal_db"] == "0" :
    if not "mapping_bias" in config["PureCN"].keys() :
        sys.exit("Missing parameters mapping_bias")
    else :
        if not os.path.exists(config["PureCN"]["mapping_bias"]) :
            sys.exit("%s does not exist"%config["PureCN"]["mapping_bias"])
        print("pon : %s"%config["PureCN"]["mapping_bias"])

if not "run" in config["sequenza"].keys() :
    run_sequenza = False
else :
    if config["sequenza"]["run"] == "1" :
        run_sequenza = True
    else :
        run_sequenza = False

if run_sequenza is True and config["genome"]["version"] != "hg19" :
    sys.exit("Sequenza must be run with hg19")

print(vc_list_snv_germline)
print(vc_list_indel_germline)
print(vc_list_snv_somatic)
print(vc_list_indel_somatic)

#================================================================#
#                    Variables from analysis sheet
#================================================================#

samples_dict = {}

SAMPLES_TUMOR = []
SAMPLES_TUMOR_DICT = {}
SAMPLES_NORMAL = []
TUMOR = []
NORMAL = []
SEQ_LIST =[]

CHROMS = ["chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19","chr20","chr21","chr22","chrX","chrY"]

combined_samples = {}
combined_names = {}
samples_type_dict = {}
samples_dict = {}

#Fastq name format must be :
#Sample_S1_L001_R1_001.fastq.gz or
#Sample_S1_R1_001.fastq.gz or
#Sample_S1_R1.fastq.gz or
#Sample_R1.fastq.gz

samples = pd.read_table(config["metadata"]["analysis_sheet"]).set_index("samples",drop=False)
for index, row in samples.iterrows():
    seq_name = re.search("^([\w\-\_]+)[_S\d+]?_?[L\d{3}]?_R(\d)(_001)?\.fastq(\.gz)?$",row["fq1"]).group(1) if re.search("^([\w\-\_]+)[_S\d+]?_?[L\d{3}]?_R(\d)(_001)?\.fastq(\.gz)?$",row["fq1"]) else None
    SEQ_LIST.append(seq_name)
    if row["samples"] in samples_dict.keys() :
        if row["type"] in samples_dict[row["samples"]].keys() :
            samples_dict[row["samples"]][row["type"]][seq_name] = [row["fq1"], row["fq2"]]
        else :
            samples_dict[row["samples"]][row["type"]] = {}
            samples_dict[row["samples"]][row["type"]][seq_name] = [row["fq1"], row["fq2"]]
    else :
        samples_dict[row["samples"]] = {}
        if row["type"] in samples_dict[row["samples"]].keys() :
            samples_dict[row["samples"]][row["type"]][seq_name] = [row["fq1"], row["fq2"]]
        else :
            samples_dict[row["samples"]][row["type"]] = {}
            samples_dict[row["samples"]][row["type"]][seq_name] = [row["fq1"], row["fq2"]]

SAMPLES = list(samples_dict.keys())

for sample in samples_dict.keys() :
    seq_name_normal = list(samples_dict[sample]["Normal"].keys())[0]
    SAMPLES_NORMAL.append(seq_name_normal)
    seq_name_tumor_list=[]
    for seq_type in samples_dict[sample].keys():
        if seq_type != "Normal" :
            seq_name_tumor = list(samples_dict[sample][seq_type].keys())[0]
            combined_samples[seq_name_tumor] = seq_name_normal
            SAMPLES_TUMOR.append(seq_name_tumor)
            seq_name_tumor_list.append(seq_name_tumor)
            samples_type_dict[seq_name_tumor] = seq_type
            SAMPLES_TUMOR_DICT[sample]=seq_name_tumor_list
    
output_analysis = "/analyse_"+config["metadata"]["date"]

SOMATIC_VC_SNV = []
SOMATIC_VC_INDEL = []
SOMATIC_SNV_ANNOT = []
SOMATIC_INDEL_ANNOT = []
SOMATIC_SV = []
MSI_STATUT = []
SEQUENZA = []
CROSS_CHECK_FINGERPRINTS = []
MODEL_SEGMENTS = []
CALLED_SEGMENTS = []
PLOT_MODEL = []
PURE_CN = []

p=re.compile("^Tumor\d+")

MAPPING=expand(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST)
QC=expand(config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.bam.qc",zip,sample=samples["samples"], seq_type=samples["type"] ,seq_name=SEQ_LIST)
MERGE_QC=config["dir"]["base"]+output_analysis+"/bam.stats"
MUTECT2_PON=expand(config["dir"]["base"]+"/{sample}/Normal/Mutect2/{seq_name}.Mutect2.for.pon.vcf.gz",zip,sample=samples["samples"][samples["type"]=="Normal"],seq_name=SAMPLES_NORMAL)
GERMLINE_SNP_ANNOT=expand(config["dir"]["base"]+"/{sample}/Normal/{seq_name}.germline.snv.result",zip,sample=samples["samples"][samples["type"]=="Normal"],seq_name=SAMPLES_NORMAL)
HLA_TYPE=expand(config["dir"]["base"]+"/{sample}/Normal/Optitype/{seq_name}_result.tsv",zip,sample=samples["samples"][samples["type"]=="Normal"],seq_name=SAMPLES_NORMAL)
GERMLINE_INDEL_ANNOT=expand(config["dir"]["base"]+"/{sample}/Normal/{seq_name}.germline.indel.result",zip,sample=samples["samples"][samples["type"]=="Normal"],seq_name=SAMPLES_NORMAL)
MERGE_SNV_GERMLINE=config["dir"]["base"]+"/germline.snv.filtered.txt"
MERGE_INDEL_GERMLINE=config["dir"]["base"]+"/germline.indel.filtered.txt"
IMPORT_SNV_GERMLINE=config["dir"]["base"]+output_analysis+"/germline.snv.import.csv"
IMPORT_INDEL_GERMLINE=config["dir"]["base"]+output_analysis+"/germline.indel.import.csv"


COLLECT_READS=expand(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.counts.hdf5",zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST)
COLLECT_ALLELIC=expand(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.allelicCounts.tsv",zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST)
DENOISED_CR=expand(config["dir"]["base"]+"/{sample}/{seq_type}/GATK4_CNA/{seq_name}.denoisedCR.tsv",zip,sample=samples["samples"][samples["type"]!="Normal"],seq_type=[t for t in samples["type"] if p.match(t)],seq_name=SAMPLES_TUMOR)
PLOT_DENOISED_CR=expand(config["dir"]["base"]+"/{sample}/{seq_type}/GATK4_CNA/plots/{seq_name}.denoised.png",zip,sample=samples["samples"][samples["type"]!="Normal"],seq_type=[t for t in samples["type"] if p.match(t)],seq_name=SAMPLES_TUMOR)

if mutect2_tumor_only is True :
    MUTECT2_TO=expand(config["dir"]["base"]+"/{sample}/{seq_type}/Mutect2/{seq_name}.Mutect2.tumor_only.filtered.vcf",zip,sample=samples["samples"][samples["type"]!="Normal"],seq_type=[t for t in samples["type"] if p.match(t)],seq_name=SAMPLES_TUMOR)
else :
    MUTECT2_TO = []

if run_purecn is True :
    PURE_CN_COV=expand(config["dir"]["base"]+"/{sample}/{seq_type}/PureCN/{seq_name}.sort.RG.dedup.recall_coverage_loess.txt.gz",zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST)
else :
    PURE_CN_COV=[]

for sample in SAMPLES :
    SOMATIC_VC_SNV = SOMATIC_VC_SNV + expand(expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{{variant_caller}}/{seq_name}_vs_{normal}.{{variant_caller}}.somatic.snv.normalized.vcf",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]] ,seq_name=SAMPLES_TUMOR_DICT[sample]),variant_caller=vc_list_snv_somatic)
    SOMATIC_VC_INDEL = SOMATIC_VC_INDEL + expand(expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{{variant_caller}}/{seq_name}_vs_{normal}.{{variant_caller}}.somatic.indel.normalized.vcf",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]] ,seq_name=SAMPLES_TUMOR_DICT[sample]),variant_caller=vc_list_indel_somatic)
    SOMATIC_SNV_ANNOT = SOMATIC_SNV_ANNOT + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.snv.result",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]],seq_name=SAMPLES_TUMOR_DICT[sample])
    SOMATIC_INDEL_ANNOT = SOMATIC_INDEL_ANNOT + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.indel.result",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]],seq_name=SAMPLES_TUMOR_DICT[sample])
    SOMATIC_SV = SOMATIC_SV + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}_allSVFiltered_functional.txt",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]],seq_name=SAMPLES_TUMOR_DICT[sample])
    MSI_STATUT = MSI_STATUT + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.msi",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]] ,seq_name=SAMPLES_TUMOR_DICT[sample])
    CROSS_CHECK_FINGERPRINTS = CROSS_CHECK_FINGERPRINTS + expand(config["dir"]["base"]+"/{sample}/{seq_name}.crosscheck_metrics",sample=sample, seq_name=SAMPLES_TUMOR_DICT[sample])
    
    if run_sequenza is True :
        SEQUENZA = SEQUENZA + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/Sequenza/{seq_name}_vs_{normal}.seqz.bin50.gz_segments.txt",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]] ,seq_name=SAMPLES_TUMOR_DICT[sample])
    
    if run_gatk4_cna is True :
        MODEL_SEGMENTS = MODEL_SEGMENTS + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.modelFinal.seg",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]] ,seq_name=SAMPLES_TUMOR_DICT[sample])
        CALLED_SEGMENTS = CALLED_SEGMENTS + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.called.seg",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]] ,seq_name=SAMPLES_TUMOR_DICT[sample])
        PLOT_MODEL = PLOT_MODEL + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/plots/{seq_name}_vs_{normal}.modeled.png",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]] ,seq_name=SAMPLES_TUMOR_DICT[sample])

    if run_purecn is True :
        PURE_CN= PURE_CN + expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/PureCN/{seq_name}_vs_{normal}_dnacopy.seg",sample=sample, normal=combined_samples[SAMPLES_TUMOR_DICT[sample][0]] ,seq_name=SAMPLES_TUMOR_DICT[sample])


MERGE_SNV_SOMATIC=config["dir"]["base"]+"/somatic.snv.filtered.txt"
MERGE_INDEL_SOMATIC=config["dir"]["base"]+"/somatic.indel.filtered.txt"
IMPORT_SNV_SOMATIC=config["dir"]["base"]+output_analysis+"/somatic.snv.import.csv"
IMPORT_INDEL_SOMATIC=config["dir"]["base"]+output_analysis+"/somatic.indel.import.csv"
MERGE_MSI=config["dir"]["base"]+output_analysis+"/merge.msi"
MULTI_QC=config["dir"]["base"]+output_analysis+"/multiqc_report.html"
PON_VCF=output_dir+"/pon.vcf.gz"


# MERGE_SV_SOMATIC=config["dir"]["base"]+"/somatic.sv.filtered.txt",
# FUNCOTATOR=expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/Funcotator/{seq_name}_vs_{normal}.variants.funcotated.maf",zip,tumor=TUMOR, normal=NORMAL,seq_name=SAMPLES_TUMOR)
# CN=expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2CN/{seq_name}_vs_{normal}.copynumber.called",zip,tumor=TUMOR, normal=NORMAL,seq_name=SAMPLES_TUMOR)

#================================================================#
#                      Input Functions
#================================================================#
#get snv somatic vcf files
def input_germline_snv(wildcards):
    tab = expand(expand(config["dir"]["base"]+"/{sample}/Normal/{{variant_caller}}/{seq_name}.{{variant_caller}}.germline.snv.normalized.vcf",zip,sample=wildcards.sample,seq_name=wildcards.seq_name),variant_caller=vc_list_snv_germline)
    return tab

def input_germline_snv_params(wildcards):
    params = []
    tab = expand(expand(config["dir"]["base"]+"/{sample}/Normal/{{variant_caller}}/{seq_name}.{{variant_caller}}.germline.snv.normalized.vcf",zip,sample=wildcards.sample,seq_name=wildcards.seq_name),variant_caller=vc_list_snv_germline)
    for elt in tab :
        for vc in vc_list_snv_germline :
            if re.search("/%s/"%vc, elt) :
                params.append("--%s %s"%(vc, elt))
    return params

#get indel germline vcf files
def input_germline_indel(wildcards):
    tab = expand(expand(config["dir"]["base"]+"/{sample}/Normal/{{variant_caller}}/{seq_name}.{{variant_caller}}.germline.indel.normalized.vcf",zip,sample=wildcards.sample,seq_name=wildcards.seq_name),variant_caller=vc_list_indel_germline)
    return tab

def input_germline_indel_params(wildcards):
    params = []
    tab = expand(expand(config["dir"]["base"]+"/{sample}/Normal/{{variant_caller}}/{seq_name}.{{variant_caller}}.germline.indel.normalized.vcf",zip,sample=wildcards.sample,seq_name=wildcards.seq_name),variant_caller=vc_list_indel_germline)
    for elt in tab :
        for vc in vc_list_indel_germline :
            if re.search("/%s/"%vc, elt) :
                params.append("--%s %s"%(vc, elt))
    return params


#get snv somatic vcf files
def input_somatic_snv(wildcards):
    tab = expand(expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{{variant_caller}}/{seq_name}_vs_{normal}.{{variant_caller}}.somatic.snv.normalized.vcf",sample=wildcards.sample, normal=wildcards.normal ,seq_name=wildcards.seq_name),variant_caller=vc_list_snv_somatic)
    return tab

def input_somatic_snv_params(wildcards):
    params = []
    tab = expand(expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{{variant_caller}}/{seq_name}_vs_{normal}.{{variant_caller}}.somatic.snv.normalized.vcf",sample=wildcards.sample, normal=wildcards.normal ,seq_name=wildcards.seq_name),variant_caller=vc_list_snv_somatic)
    for elt in tab :
        for vc in vc_list_snv_somatic :
            if re.search("/%s/"%vc, elt) :
                params.append("--%s %s"%(vc, elt))
    return params

#get indel somatic vcf files
def input_somatic_indel(wildcards):
    tab = expand(expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{{variant_caller}}/{seq_name}_vs_{normal}.{{variant_caller}}.somatic.indel.normalized.vcf",zip,sample=wildcards.sample, normal=wildcards.normal,seq_name=wildcards.seq_name),variant_caller=vc_list_indel_somatic)
    return tab

def input_somatic_indel_params(wildcards):
    params = []
    tab = expand(expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{{variant_caller}}/{seq_name}_vs_{normal}.{{variant_caller}}.somatic.indel.normalized.vcf",zip,sample=wildcards.sample, normal=wildcards.normal,seq_name=wildcards.seq_name),variant_caller=vc_list_indel_somatic)
    for elt in tab :
        for vc in vc_list_indel_somatic :
            if re.search("/%s/"%vc, elt) :
                params.append("--%s %s"%(vc, elt))
    return params

def input_merge_snv(wildcards):
    tab = SOMATIC_SNV_ANNOT
    return tab

def input_merge_indel(wildcards):
    tab = SOMATIC_INDEL_ANNOT
    return tab

def input_merge_msi(wildcards):
    tab = MSI_STATUT
    return tab

def fastqc_output(wildcards):
    if trimming is True :
        if paired is True :
            if molecular_barcode is True :
                return expand(config["dir"]["base"]+"/"+wildcards.sample+"/"+wildcards.seq_type+"/"+"report_"+wildcards.seq_name+"/"+wildcards.seq_name+"_{strand}_001.paired.trim_fastqc.html", strand=["R1","R3"])
            else :
                return expand(config["dir"]["base"]+"/"+wildcards.sample+"/"+wildcards.seq_type+"/"+"report_"+wildcards.seq_name+"/"+wildcards.seq_name+"_{strand}_001.paired.trim_fastqc.html", strand=["R1","R2"])
        else :
            return expand(config["dir"]["base"]+"/"+wildcards.sample+"/"+wildcards.seq_type+"/"+"report_"+wildcards.seq_name+"/"+wildcards.seq_name+"_{strand}_001.paired.trim_fastqc.html", strand=["R1"])
    else :
        if paired is True :
            if molecular_barcode is True :
                return expand(config["dir"]["base"]+"/"+wildcards.sample+"/"+wildcards.seq_type+"/"+"report_"+wildcards.seq_name+"/"+wildcards.seq_name+"_{strand}_001_fastqc.html", strand=["R1","R3"])
            else :
                return expand(config["dir"]["base"]+"/"+wildcards.sample+"/"+wildcards.seq_type+"/"+"report_"+wildcards.seq_name+"/"+wildcards.seq_name+"_{strand}_001_fastqc.html", strand=["R1","R2"])
        else :
            return expand(config["dir"]["base"]+"/"+wildcards.sample+"/"+wildcards.seq_type+"/"+"report_"+wildcards.seq_name+"/"+wildcards.seq_name+"_{strand}_001_fastqc.html", strand=["R1"])

def fastqc_output_zip(wildcards):
    if trimming is True :
        if paired is True :
            if molecular_barcode is True :
                return expand(expand(config["dir"]["base"]+"/{sample}/{seq_type}/"+"report_{seq_name}/{seq_name}_{{strand}}_001.paired.trim_fastqc.zip", zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST),strand=["R1","R3"])
            else :
                return expand(expand(config["dir"]["base"]+"/{sample}/{seq_type}/"+"report_{seq_name}/{seq_name}_{strand}_001.paired.trim_fastqc.zip", zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST),strand=["R1","R2"])
        else :
            return expand(config["dir"]["base"]+"/{sample}/{seq_type}/"+"report_{seq_name}/{seq_name}_R1_001.paired.trim_fastqc.zip", zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST)
    else :
        if paired is True :
            if molecular_barcode is True :
                return expand(expand(config["dir"]["base"]+"/{sample}/{seq_type}/"+"report_{seq_name}/{seq_name}_{{strand}}_001_fastqc.zip", zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST),strand=["R1","R3"])
            else :
                return expand(expand(config["dir"]["base"]+"/{sample}/{seq_type}/"+"report_{seq_name}/{seq_name}_{{strand}}_001_fastqc.zip", zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST),strand=["R1","R2"])
        else :
            return expand(config["dir"]["base"]+"/{sample}/{seq_type}/"+"report_{seq_name}/{seq_name}_R1_001_fastqc.zip",  zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST)


#get bam and index from seq_name
def get_tumor_bam(wildcards):
    tumor_seq = wildcards.seq_name
    seq_type =samples_type_dict[tumor_seq]
    return [config["dir"]["base"]+"/"+wildcards.sample+"/"+seq_type+"/"+tumor_seq+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",config["dir"]["base"]+"/"+wildcards.sample+"/"+seq_type+"/"+tumor_seq+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai"]


#get input tumor normal bam files
def get_paired_samples(wildcards):
    tumor_seq = wildcards.seq_name
    normal_seq = combined_samples[tumor_seq]
    seq_type =samples_type_dict[tumor_seq]
    return [config["dir"]["base"]+"/"+wildcards.sample+"/"+seq_type+"/"+tumor_seq+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",config["dir"]["base"]+"/"+wildcards.sample+"/"+"Normal"+"/"+normal_seq+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam"]

def get_filter_paired_samples(wildcards):
    tumor_seq = wildcards.seq_name
    normal_seq = combined_samples[tumor_seq]
    seq_type =samples_type_dict[tumor_seq] 
    return [config["dir"]["base"]+"/"+wildcards.sample+"/"+seq_type+"/"+tumor_seq+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall.filter."+"bam",config["dir"]["base"]+"/"+wildcards.sample+"/"+"Normal"+"/"+normal_seq+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall.filter."+"bam"]


#get input tumor normal bam files
def get_paired_pileup(wildcards):
    tumor_seq = wildcards.seq_name
    normal_seq = combined_samples[tumor_seq]
    seq_type =samples_type_dict[tumor_seq]
    return [config["dir"]["base"]+"/"+wildcards.sample+"/"+seq_type+"/report_"+tumor_seq+"/"+tumor_seq+".pileupsummaries.table",config["dir"]["base"]+"/"+wildcards.sample+"/"+"Normal"+"/report_"+normal_seq+"/"+normal_seq+".pileupsummaries.table"]


#get input tumor normal bam files
def get_paired_allelic(wildcards):
    tumor_seq = wildcards.seq_name
    normal_seq = combined_samples[tumor_seq]
    seq_type =samples_type_dict[tumor_seq]
    return [config["dir"]["base"]+"/"+wildcards.sample+"/"+seq_type+"/"+tumor_seq+".allelicCounts.tsv",config["dir"]["base"]+"/"+wildcards.sample+"/"+"Normal"+"/"+normal_seq+".allelicCounts.tsv",config["dir"]["base"]+"/"+wildcards.sample+"/"+seq_type+"/GATK4_CNA/"+tumor_seq+".denoisedCR.tsv"]

#get input tumor normal bam files
def get_paired_coverage_loess(wildcards):
    tumor_seq = wildcards.seq_name
    normal_seq = combined_samples[tumor_seq]
    seq_type =samples_type_dict[tumor_seq]
    return [config["dir"]["base"]+"/"+wildcards.sample+"/"+seq_type+"/PureCN/"+tumor_seq+".sort.RG.dedup.recall_coverage_loess.txt.gz",config["dir"]["base"]+"/"+wildcards.sample+"/"+"Normal"+"/PureCN/"+normal_seq+".sort.RG.dedup.recall_coverage_loess.txt.gz"]


#get input trimmed fastq for the alignment
def bwa_input(wildcards):
    if trimming is True :
        if paired is True :
            if molecular_barcode is True :
                return expand(fastq_dir+"/"+"{seq_name}_{strand}_001.paired.trim.fastq.gz", strand=["R1","R3"], seq_name=wildcards.seq_name)
            else :
                return expand(fastq_dir+"/"+"{seq_name}_{strand}_001.paired.trim.fastq.gz", strand=["R1","R2"], seq_name=wildcards.seq_name)
        else :
            return expand(fastq_dir+"/"+"{seq_name}_{strand}_001.trim.fastq.gz", strand=["R1"], seq_name=wildcards.seq_name)
    else :
        if paired is True :
            if molecular_barcode is True :
                return expand(fastq_dir+"/"+"{seq_name}_{strand}_001.fastq.gz", strand=["R1","R3"], seq_name=wildcards.seq_name)
            else :
                return expand(fastq_dir+"/"+"{seq_name}_{strand}_001.fastq.gz", strand=["R1","R2"], seq_name=wildcards.seq_name)
        else :
            return expand(fastq_dir+"/"+"{seq_name}_{strand}_001.fastq.gz", strand=["R1"], seq_name=wildcards.seq_name)

#get input trimmed fastq for the alignment
def razer_input(wildcards):
    if paired is True :
        return expand(fastq_dir+"/"+"{seq_name}_{strand}_001.fastq.gz", strand=["R1","R2"], seq_name=wildcards.seq_name)
    else :
        return expand(fastq_dir+"/"+"{seq_name}_{strand}_001.fastq.gz", strand=["R1"], seq_name=wildcards.seq_name)


#================================================================#
#                      Workflow
#================================================================#

#MAIN
if config["tools"]["sv_calling"] == "Delly" :
    rule all :
        input:
            MAPPING_TUMOR,
            MAPPING_NORMAL,
            QC_NORMAL,
            QC_TUMOR,
            COV_NORMAL,
            COV_TUMOR,
            SOMATIC_VC_SV,
            SNP_PILEUP,
            MSI_STATUT,
            SOMATIC_ANNOT,
            GERMLINE_ANNOT,
            MERGE_SNV_SOMATIC,
            MERGE_INDEL_SOMATIC,
            MERGE_SV_SOMATIC,
            MERGE_SNV_GERMLINE,
            MERGE_INDEL_GERMLINE,
            IMPORT_SNV_SOMATIC,
            IMPORT_INDEL_SOMATIC,
            IMPORT_SNV_GERMLINE,
            IMPORT_INDEL_GERMLINE,
            MERGE_QC,
            MERGE_MSI,

else :
    rule all :
        input:
            MAPPING,
            QC,
            #QC_NORMAL,
            #QC_TUMOR,
            #COV_NORMAL,
            #COV_TUMOR,
            #MSI_STATUT,
            #MUTECT2_PON,
            #GERMLINE_SNP_ANNOT,
            #GERMLINE_INDEL_ANNOT,
            #HLA_TYPE,
            #SOMATIC_VC_SNV,
            #SOMATIC_VC_INDEL,
            #SOMATIC_SNV_ANNOT,
            #SOMATIC_INDEL_ANNOT,
            #SOMATIC_SV,
            #MERGE_SNV_SOMATIC,
            #MERGE_INDEL_SOMATIC,
            #MERGE_SNV_GERMLINE,
            #MERGE_INDEL_GERMLINE,
            #SEQUENZA,
            #CN,
            #COLLECT_READS,
            #COLLECT_ALLELIC,
            #DENOISED_CR,
            #PLOT_DENOISED_CR,
            #MODEL_SEGMENTS,
            #CALLED_SEGMENTS,
            #PLOT_MODEL,
            #MUTECT2_TO,
            PURE_CN_COV,
            PURE_CN,
            PON_VCF,
            #CROSS_CHECK_FINGERPRINTS,
            #IMPORT_SNV_SOMATIC,
            #IMPORT_INDEL_SOMATIC,
            #IMPORT_SNV_GERMLINE,
            #IMPORT_INDEL_GERMLINE,
            MERGE_QC,
            MERGE_MSI,
            MULTI_QC


#Trim Fastq
if paired is True :

    if molecular_barcode is True :

        if trimming is True :

            rule trim:
                input:
                    fastq_dir+"/"+"{seq_name}_R1_001.fastq.gz",
                    fastq_dir+"/"+"{seq_name}_R3_001.fastq.gz",
                output:
                    r1_paired=temp(fastq_dir+"/"+"{seq_name}_R1_001.paired.trim.fastq.gz"),
                    r1_unpaired=temp(fastq_dir+"/"+"{seq_name}_R1_001.unpaired.trim.fastq.gz"),
                    r2_paired=temp(fastq_dir+"/"+"{seq_name}_R3_001.paired.trim.fastq.gz"),
                    r2_unpaired=temp(fastq_dir+"/"+"{seq_name}_R3_001.unpaired.trim.fastq.gz"),
                container:
                    "docker://ngsom/tumorseq"
                params:
                    crop=params_trim_crop
                shell:"java -Xmx16G -jar /usr/share/java/Trimmomatic-0.39/trimmomatic-0.39.jar PE -threads 8 -phred33 {input} {output.r1_paired} {output.r1_unpaired} {output.r2_paired} {output.r2_unpaired} HEADCROP:8 SLIDINGWINDOW:4:15 CROP:{params.crop}"

         	#Fastqc
            rule fastqc:
                input:
                    bwa_input,
                output:
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001.paired.trim_fastqc.html",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R3_001.paired.trim_fastqc.html",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001.paired.trim_fastqc.zip",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R3_001.paired.trim_fastqc.zip",
                params:
                    base_dir=output_dir
                container:
                    "docker://ngsom/tumorseq"
                shell:
            	    "fastqc {input} -o {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/report_{wildcards.seq_name} -t 8"

        else :
		
            rule fastqc:
                input:
                    bwa_input,
                output:
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001_fastqc.html",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R3_001_fastqc.html",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001_fastqc.zip",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R3_001_fastqc.zip",
                params:
                    base_dir=output_dir
                container:
                    "docker://ngsom/tumorseq"
                shell:
            	    "fastqc {input} -o {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/report_{wildcards.seq_name} -t 8"



    else :

        if trimming is True :

            rule trim:
                input:
                    fastq_dir+"/"+"{seq_name}_R1_001.fastq.gz",
                    fastq_dir+"/"+"{seq_name}_R2_001.fastq.gz",
                output:
                    r1_paired=temp(fastq_dir+"/"+"{seq_name}_R1_001.paired.trim.fastq.gz"),
                    r1_unpaired=temp(fastq_dir+"/"+"{seq_name}_R1_001.unpaired.trim.fastq.gz"),
                    r2_paired=temp(fastq_dir+"/"+"{seq_name}_R2_001.paired.trim.fastq.gz"),
                    r2_unpaired=temp(fastq_dir+"/"+"{seq_name}_R2_001.unpaired.trim.fastq.gz"),
                container:
                    "docker://ngsom/tumorseq"
                benchmark:
                    "benchmarks/{seq_name}.trim.txt"
                params:
                    crop=params_trim_crop
                shell:"java -Xmx16G -jar /usr/share/java/Trimmomatic-0.39/trimmomatic-0.39.jar PE -threads 8 -phred33 {input} {output.r1_paired} {output.r1_unpaired} {output.r2_paired} {output.r2_unpaired} HEADCROP:8 SLIDINGWINDOW:4:15 CROP:{params.crop}"

         	#Fastqc
            rule fastqc:
                input:
                    bwa_input,
                output:
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001.paired.trim_fastqc.html",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R2_001.paired.trim_fastqc.html",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001.paired.trim_fastqc.zip",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R2_001.paired.trim_fastqc.zip",
                params:
                    base_dir=output_dir
                container:
                    "docker://ngsom/tumorseq"
                benchmark:
                    "benchmarks/{sample}_{seq_type}_{seq_name}.fastqc.txt"
                shell:
            	    "fastqc {input} -o {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/report_{wildcards.seq_name} -t 8"

        else :

            rule fastqc:
                input:
                    bwa_input,
                output:
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001_fastqc.html",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R2_001_fastqc.html",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001_fastqc.zip",
                    config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R2_001_fastqc.zip",
                params:
                    base_dir=output_dir
                container:
                    "docker://ngsom/tumorseq"
                benchmark:
                    "benchmarks/{sample}_{seq_type}_{seq_name}.fastqc.txt"
                shell:
            	    "fastqc {input} -o {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/report_{wildcards.seq_name} -t 8"

else :

    rule trim:
        input:
            fastq_dir+"/"+"{seq_name}_R1_001.fastq.gz",
        output:
            temp(fastq_dir+"/"+"{seq_name}_R1_001.trim.fastq.gz"),
        container:
            "docker://ngsom/tumorseq"
        benchmark:
            "benchmarks/{seq_name}.trim.txt"
        shell:"java -Xmx16G -jar /usr/share/java/Trimmomatic-0.39/trimmomatic-0.39.jar SE -threads 8 -phred33 {input} {output} HEADCROP:8 SLIDINGWINDOW:4:15 CROP:250"

     #Fastqc
    rule fastqc:
        input:
            bwa_input,
        output:
            config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001.paired.trim_fastqc.html",
            config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}_R1_001.paired.trim_fastqc.zip",
        params:
            base_dir=output_dir
        container:
            "docker://ngsom/tumorseq"
        benchmark:
            "benchmarks/{sample}_{seq_type}_{seq_name}.trim.txt"
        shell:
            "fastqc {input} -o {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/report_{wildcards.seq_name} -t 8"

#Mapping with BWA mem
rule bwa_map:
    input:
        config["genome"]["fasta_file"],
        bwa_input,
    output:
        temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.bam")
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.bwa_map.txt"
    shell:
        "bwa mem -t 8 -M {input} | samtools view -Sb - > {output}"

rule LocatIt:
    input:
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.bam",
        fastq_index=fastq_dir+"/"+"{seq_name}_R2_001.fastq.gz"
    output:
        temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.LocatIt.bam")
    container:
        "docker://ngsom/tumorseq"
    shell:
        "LocatIt -Xmx120G -PM:xm,Q:xq,q:nQ,r:nR,I:ni -q 25 -m 1 -U -IS -OB -C -i -r -c 2500 -l {input.target} -o {output} {input.bam} {input.fastq_index}"

#Sort Bam Files
rule samtools_sort:
    input:
        config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"bam"
    output:
        temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort.bam")
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.samtools_sort.txt"
    params:
        base_dir=output_dir
    shell:
        "samtools sort --threads 6 -m 2G -T {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/{wildcards.seq_name} -O bam {input} > {output}"


#Index Bam Files
rule samtools_index :
    input:
        config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort.bam"
    output:
        temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort.bam.bai")
    container:
        "docker://ngsom/tumorseq"
    shell:
        "samtools index {input}"

#Remove Non uniq map reads
rule samtools_uniq :
    input:
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort.bam",
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort.bam.bai",
    output:
        temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+".uniq."+"bam")
    container:
        "docker://ngsom/tumorseq"
    shell:
        "samtools view -b -q 1 {input.bam} > {output}"

#Index Bam files
rule samtools_index_uniq :
    input:
        config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.sort.uniq.bam"
    output:
        temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.sort.uniq.bam.bai")
    container:
        "docker://ngsom/tumorseq"
    shell:
        "samtools index {input}"

#Add RG group
rule picard_add_group :
    input:
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"bam",
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"bam.bai",
    output:
        temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam")
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.picard_add_group.txt"
    params:
        RGLB=config['metadata']['design_name'],
        RGPL=config["metadata"]["platform"],
        RGCN=config["metadata"]["center"],
        RGDT=config['metadata']['date'],
    shell :"""java -XX:ParallelGCThreads=2 -Xmx16G -jar /usr/share/java/picard.jar AddOrReplaceReadGroups \
        -I {input.bam} \
        -O {output} \
        -RGID {wildcards.seq_name} \
        -RGLB {params.RGLB} \
        -RGPL {params.RGPL} \
        -RGPU barcode \
        -RGSM {wildcards.seq_name} \
        -RGCN {params.RGCN} \
        -RGDS description \
        -RGDT {params.RGDT} \
        -VALIDATION_STRINGENCY SILENT \
        -CREATE_INDEX false"""

#Index Bam files
rule samtools_index_rg :
    input:
        config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam"
    output:
        temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam.bai")
    container:
        "docker://ngsom/tumorseq"
    shell:
        "samtools index {input}"


#Dedup Reads
#rule GATK_dedup_spark :
#    input:
#        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam",
#        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam.bai",
#        ref=config["genome"]["fasta_file"]
#    output:
#        bam=temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+".dedup."+"bam"),
#        index=temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+".dedup."+"bam.bai")
#    container:
#        "docker://broadinstitute/gatk:4.2.2.0"
#    params:
#        base_dir=output_dir
#    shell:
#        """
#        mkdir {params.base_dir}/{wildcards.sample}/{wildcards.type_of_sample}/tmp
#        gatk MarkDuplicatesSpark \
#        --conf 'spark.executor.cores=8' \
#        --conf 'spark.executor.instances=7' \
#        --conf 'spark.executor.memory=8G' \
#        --tmp-dir {params.base_dir}/{wildcards.sample}/{wildcards.type_of_sample}/tmp \
#        -R {input.ref} \
#        -I {input.bam} \
#        -O {output.bam}
#        rm -r {params.base_dir}/{wildcards.sample}/{wildcards.type_of_sample}/tmp
#        """

#rule GATK_dedup :
#    input:
#        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam",
#        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam.bai",
#        ref=config["genome"]["fasta_file"]
#    output:
#        bam=temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+".dedup."+"bam")
#    container:
#        "docker://broadinstitute/gatk:4.2.2.0"
#    params:
#        base_dir=output_dir
#    shell:
#        """
#        gatk MarkDuplicates \
#        --java-options -Xmx16G \
#        -R {input.ref} \
#        -I {input.bam} \
#        -M {params.base_dir}/{wildcards.sample}/{wildcards.type_of_sample}/{wildcards.seq_name}.dedup.metrics \
#        -O {output.bam}
#        """

rule sambamba_dedup :
    input:
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam",
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG."+"bam.bai",
        ref=config["genome"]["fasta_file"]
    output:
        bam=temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+".dedup."+"bam")
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.sambamba_dedup.txt"
    params:
        base_dir=output_dir
    shell:
        """
        mkdir {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/tmp
        /opt/sambamba-0.8.2-linux-amd64-static markdup --nthreads 8 --tmpdir {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/tmp {input.bam} {output}
        """

#Index Bam files
rule samtools_index_dedup :
    input:
        config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+".dedup."+"bam"
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+".dedup."+"bam.bai"
    container:
        "docker://ngsom/tumorseq"
    shell:
        "samtools index {input}"

#rule GATK_recalibrate_spark :
#    input:
#        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"bam",
#        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"bam.bai",
#        ref=config["genome"]["fasta_file"],
#        known_site=config["genome"]["known_site"],
#        target=config["metadata"]["design"]
#    output:
#        grp=temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.grp"),
#        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
#        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai"
#    container:
#        "docker://broadinstitute/gatk:4.2.2.0"
#    params:
#        base_dir=output_dir
#    shell:"""
#        mkdir {params.base_dir}/{wildcards.sample}/{wildcards.type_of_sample}/tmp
#        gatk BaseRecalibratorSpark \
#        --conf 'spark.executor.cores=8' \
#        --conf 'spark.executor.instances=7' \
#        --conf 'spark.executor.memory=8G' \
#        --tmp-dir {params.base_dir}/{wildcards.sample}/{wildcards.type_of_sample}/tmp \
#        -R {input.ref} \
#        -I {input.bam} \
#        --known-sites {input.known_site} \
#        -O {output.grp} 
#        gatk ApplyBQSRSpark \
#        --conf 'spark.executor.cores=8' \
#        --conf 'spark.executor.instances=7' \
#        --conf 'spark.executor.memory=8G' \
#        --tmp-dir {params.base_dir}/{wildcards.sample}/{wildcards.type_of_sample}/tmp \
#        -R {input.ref} \
#        -I {input.bam} \
#        --bqsr-recal-file {output.grp} \
#        -O {output.bam}
#        rm -r {params.base_dir}/{wildcards.sample}/{wildcards.type_of_sample}/tmp
#        """

rule GATK_recalibrate :
    input:
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"bam",
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"bam.bai",
        ref=config["genome"]["fasta_file"],
        known_site=config["genome"]["known_site"],
        target=config["metadata"]["design"]
    output:
        grp=temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.grp"),
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bai",
        index2=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.GATK_recalibrate.txt"
    params:
        base_dir=output_dir
    shell:"""
        gatk BaseRecalibrator \
        --java-options -Xmx16G \
        -R {input.ref} \
        -I {input.bam} \
        --known-sites {input.known_site} \
        -O {output.grp} 
        gatk ApplyBQSR \
        --java-options -Xmx16G \
        -R {input.ref} \
        -I {input.bam} \
        --bqsr-recal-file {output.grp} \
        -O {output.bam}
        cp {output.index} {output.index2}
        """

rule filter_bam :
    input:
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai"
    output:
        bam=temp(config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall.filter."+"bam"),
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall.filter."+"bam.bai"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.filter_bam.txt"
    shell:
        """
        /opt/sambamba-0.8.2-linux-amd64-static view {input.bam} --filter "not (unmapped or duplicate or secondary_alignment or failed_quality_control or supplementary)" --format bam --nthreads 8 --output-filename {output.bam}
        """

#Collect Sequencing Artifacts
rule picard_collect_seq_artifacts :
    input:
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.pre_adapter_detail_metrics.txt",
        output_dir+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.pre_adapter_summary_metrics.txt",
        output_dir+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.bait_bias_detail_metrics.txt",
        output_dir+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.bait_bias_summary_metrics.txt",
        output_dir+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.error_summary_metrics.txt"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.picard_collect_seq_artifacts.txt"
    params:
        base_dir=output_dir
    shell:
        """
        java -Xmx16G -jar /usr/share/java/picard.jar CollectSequencingArtifactMetrics \
        -R {input.ref} \
        -I {input.bam} \
        -O {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/report_{wildcards.seq_name}/{wildcards.seq_name} \
        -EXT .txt
        """

rule sambamba_flagstat :
    input:
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
    output:
        output_dir+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.flagstat.txt"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.sambamba_flagstat.txt"
    params:
        base_dir=output_dir
    shell:
        """
        /opt/sambamba-0.8.2-linux-amd64-static flagstat -t 8 {input.bam} > {output}
        """

rule PileupSummaries :
    input:
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
        exac_common=config["genome"]["exac_common"]
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.pileupsummaries.table"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.pileup_summaries.txt"
    params:
        base_dir=output_dir
    shell:
        """
        # PileupSummaries
        gatk GetPileupSummaries \
        --java-options -Xmx16G \
        --reference {input.ref} \
        -I {input.bam} \
        -V {input.exac_common} \
        -L {input.target} \
        -O {output}
        """

rule PreprocessIntervals :
    input:
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"]
    output:
        config["dir"]["base"]+"/target.preprocessed.interval_list"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/preprocessIntervals.txt"
    params:
        base_dir=output_dir
    shell:
        """
        gatk PreprocessIntervals \
        --java-options -Xmx16G \
        --reference {input.ref} \
        -L {input.target} \
        --bin-length 0 \
        --interval-merging-rule OVERLAPPING_ONLY \
        -O {output}
        """

rule CollectAllelicCounts :
    input:
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        exac_common=config["genome"]["exac_common"]
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.allelicCounts.tsv"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.CollectAllelicCounts.txt"
    params:
        base_dir=output_dir
    shell:
        """
        gatk CollectAllelicCounts \
        --java-options -Xmx16G \
        -I {input.bam} \
        --reference {input.ref} \
        -L {input.exac_common} \
        -O {output}
        """

rule CollectReadCounts :
    input:
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        target=config["dir"]["base"]+"/target.preprocessed.interval_list"
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.counts.hdf5"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.CollectReadCounts.txt"
    params:
        base_dir=output_dir
    shell:
        """
        # PileupSummaries
        gatk CollectReadCounts \
        --java-options -Xmx16G \
        -I {input.bam} \
        -L {input.target} \
        --interval-merging-rule OVERLAPPING_ONLY \
        -O {output}
        """

rule DenoiseReadCounts :
    input:
        tumor_read_counts=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}.counts.hdf5",
        pon_cna=config["GATK4_CNA"]["pon_cna"]
    output:
        standardizedCR=config["dir"]["base"]+"/{sample}/{seq_type}/GATK4_CNA/{seq_name}.standardizedCR.tsv",
        denoisedCR=config["dir"]["base"]+"/{sample}/{seq_type}/GATK4_CNA/{seq_name}.denoisedCR.tsv"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.DenoiseReadCounts.txt"
    params:
        base_dir=output_dir
    shell:
        """
        gatk DenoiseReadCounts \
        --java-options -Xmx16G \
        -I {input.tumor_read_counts} \
        --count-panel-of-normals {input.pon_cna} \
        --standardized-copy-ratios {output.standardizedCR}  \
        --denoised-copy-ratios {output.denoisedCR}
        """

rule PlotDenoiseReadCounts :
    input:
        standardizedCR=config["dir"]["base"]+"/{sample}/{seq_type}/GATK4_CNA/{seq_name}.standardizedCR.tsv",
        denoisedCR=config["dir"]["base"]+"/{sample}/{seq_type}/GATK4_CNA/{seq_name}.denoisedCR.tsv",
        genome_dict=config['GATK4_CNA']["genome_dict"]
    output:
        clean_denoised_png=config["dir"]["base"]+"/{sample}/{seq_type}/GATK4_CNA/plots/{seq_name}.denoised.png"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.PlotDenoiseReadCounts.txt"
    params:
        base_dir=output_dir
    shell:
        """
        gatk PlotDenoisedCopyRatios \
        --java-options -Xmx16G \
        --standardized-copy-ratios {input.standardizedCR} \
        --sequence-dictionary {input.genome_dict} \
        --denoised-copy-ratios {input.denoisedCR} \
        --output {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/GATK4_CNA/plots \
        --output-prefix {wildcards.seq_name}
        """

rule ModelSegments:
    input:
        paired=get_paired_allelic,
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.modelFinal.seg",
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.cr.seg",
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.hets.tsv",
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_name}_{normal}.ModelSegments.txt"
    params:
        base_dir=output_dir,
    shell:"""
        gatk ModelSegments \
        --java-options -Xmx16G \
        --denoised-copy-ratios {input.paired[2]} \
        --allelic-counts {input.paired[0]} \
        --normal-allelic-counts {input.paired[1]} \
        --output {params.base_dir}/{wildcards.sample}/SomaticAnalysis/GATK4_Allelic_CNA \
        --output-prefix {wildcards.seq_name}_vs_{wildcards.normal}
        """

rule CallCopyRatioSegments:
    input:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.cr.seg"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.called.seg"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_name}_{normal}.CallCopyRatioSegments.txt"
    params:
        base_dir=output_dir,
    shell:"""
        gatk CallCopyRatioSegments \
        --java-options -Xmx16G \
        --input {input} \
        --output {output}
        """

rule PlotModeledSegments:
    input:
        paired=get_paired_allelic,
        model=config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.modelFinal.seg",
        hets=config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/{seq_name}_vs_{normal}.hets.tsv"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/GATK4_Allelic_CNA/plots/{seq_name}_vs_{normal}.modeled.png"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_name}_{normal}.PlotModelSegments.txt"
    params:
        base_dir=output_dir,
    shell:"""
        gatk PlotModeledSegments \
        --java-options -Xmx16G \
        --denoised-copy-ratios {input.paired[2]} \
        --allelic-counts {input.hets} \
        --segments {input.model} \
        --sequence-dictionary /shared/projects/pmngs/Homo_sapiens/UCSC/hg38/Sequence/WholeGenomeFasta/genome_cna_gatk4.dict \
        --output {params.base_dir}/{wildcards.sample}/SomaticAnalysis/GATK4_Allelic_CNA/plots \
        --output-prefix {wildcards.seq_name}_vs_{wildcards.normal}
        """

rule CalculateContamination:
    input:
        paired=get_paired_pileup,
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.CalculateContamination.table"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_name}_{normal}.calculate_cont.txt"
    params:
        base_dir=output_dir,
    shell:"""
        # Calculate contamination
        gatk CalculateContamination \
        --java-options -Xmx16G \
        -I {input.paired[0]} \
        --matched-normal {input.paired[1]} \
        -O {output}
        """

rule Cross_check_fingerprints:
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
        map=config["genome"]["map_file"]
    output:
        config["dir"]["base"]+"/{sample}/{seq_name}.crosscheck_metrics"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_name}.cross_check_fingerprints.txt"
    params:
        base_dir=output_dir,
    shell:"""
        java -jar /usr/share/java/picard.jar CrosscheckFingerprints \
        --HAPLOTYPE_MAP {input.map} \
        -I {input.paired[1]} \
        -I {input.paired[0]} \
        --CROSSCHECK_BY FILE \
        --LOD_THRESHOLD -5 \
        --EXPECT_ALL_GROUPS_TO_MATCH true \
        --ALLOW_DUPLICATE_READS true \
        --OUTPUT {output} \
        --VALIDATION_STRINGENCY SILENT \
        --EXIT_CODE_WHEN_MISMATCH 0 \
        --EXIT_CODE_WHEN_NO_VALID_CHECKS 0
        """

rule bam2fq :
    input:
        hla_ref=config["genome"]["hla_ref"],
        fastq=bwa_input
    output:
        hla_1=config["dir"]["base"]+"/{sample}/Normal/Optitype/{seq_name}_hla_1.fastq",
        hla_2=config["dir"]["base"]+"/{sample}/Normal/Optitype/{seq_name}_hla_2.fastq"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:
        """
		bwa mem -t 8 -M {input.hla_ref} {input.fastq[0]} | samtools fastq -F4 - > {output.hla_1}
        bwa mem -t 8 -M {input.hla_ref} {input.fastq[1]} | samtools fastq -F4 - > {output.hla_2}
        """

rule optitype :
    input:
        fq1=config["dir"]["base"]+"/{sample}/Normal/Optitype/{seq_name}_hla_1.fastq",
        fq2=config["dir"]["base"]+"/{sample}/Normal/Optitype/{seq_name}_hla_2.fastq",
    output:
        config["dir"]["base"]+"/{sample}/Normal/Optitype/{seq_name}_result.tsv",
    container:
        "docker://fred2/optitype"
    params:
        base_dir=output_dir
    shell:
        """
		OptiTypePipeline.py -i {input.fq1} {input.fq2} --dna -v --outdir {params.base_dir}/{wildcards.sample}/Normal/Optitype --prefix {wildcards.seq_name}
        """

rule freebayesGerm :
    input :
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"]
    output :
        config["dir"]["base"]+"/{sample}/Normal/FreeBayes/{seq_name}.FreeBayes.germline.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_name}.freebayesGerm.txt"
    shell:"""
    # Variant calling with FreeBayes
    freebayes -b {input.bam} \
    -v {output} \
    -t {input.target} \
    -f {input.ref} \
    -F 0.02 \
    --min-coverage 10 \
    -C 2 \
    -m 30 \
    -q 20 \
    -R 0 \
    -S 0 \
    --pooled-discrete \
    --pooled-continuous \
    --allele-balance-priors-off
    """

rule vt_freebayesGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/FreeBayes/{seq_name}.FreeBayes.germline.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/FreeBayes/{seq_name}.FreeBayes.germline.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_freebayesGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_freebayesGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/FreeBayes/{seq_name}.FreeBayes.germline.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/FreeBayes/{seq_name}.FreeBayes.germline.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule split_snp_indel_freebayesGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/FreeBayes/{seq_name}.FreeBayes.germline.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/Normal/FreeBayes/{seq_name}.FreeBayes.germline.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/Normal/FreeBayes/{seq_name}.FreeBayes.germline.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.split_freebayesGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/FreeBayes/{wildcards.seq_name}.FreeBayes.germline.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/FreeBayes/{wildcards.seq_name}.FreeBayes.germline.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/FreeBayes/{wildcards.seq_name}.FreeBayes.germline.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/FreeBayes/{wildcards.seq_name}.FreeBayes.germline.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/FreeBayes/{wildcards.seq_name}.FreeBayes.germline.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/FreeBayes/{wildcards.seq_name}.FreeBayes.germline.snv.normalized.vcf
        """

rule GATK_haplotypecaller :
    input:
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/HaplotypeCaller/{seq_name}.HaplotypeCaller.germline.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
         "benchmarks/{sample}_{seq_name}.GATK_HC.txt"
    params:
        base_dir=output_dir
    shell:"""
        # Variant calling
        gatk HaplotypeCaller \
        --java-options -Xmx16G \
        --native-pair-hmm-threads 8 \
        --reference {input.ref} \
        -L {input.target} \
        --output  {output} \
        -I {input.bam} \
        """

rule vt_hc :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/HaplotypeCaller/{seq_name}.HaplotypeCaller.germline.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/HaplotypeCaller/{seq_name}.HaplotypeCaller.germline.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_hc.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_hc :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/HaplotypeCaller/{seq_name}.HaplotypeCaller.germline.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/HaplotypeCaller/{seq_name}.HaplotypeCaller.germline.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule split_snp_indel_hc :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/HaplotypeCaller/{seq_name}.HaplotypeCaller.germline.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/Normal/HaplotypeCaller/{seq_name}.HaplotypeCaller.germline.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/Normal/HaplotypeCaller/{seq_name}.HaplotypeCaller.germline.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.split_hc.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/HaplotypeCaller/{wildcards.seq_name}.HaplotypeCaller.germline.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/HaplotypeCaller/{wildcards.seq_name}.HaplotypeCaller.germline.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/HaplotypeCaller/{wildcards.seq_name}.HaplotypeCaller.germline.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/HaplotypeCaller/{wildcards.seq_name}.HaplotypeCaller.germline.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/HaplotypeCaller/{wildcards.seq_name}.HaplotypeCaller.germline.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/HaplotypeCaller/{wildcards.seq_name}.HaplotypeCaller.germline.snv.normalized.vcf
        """

rule platypusGerm :
    input :
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"]
    output :
        config["dir"]["base"]+"/{sample}/Normal/Platypus/{seq_name}.Platypus.germline.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.PlatypusGerm.txt"
    params:
        base_dir=output_dir,
        dedup = dedup_option_platypus
    shell:"""
        source activate platypus
        platypus callVariants --nCPU=8 --bamFiles={input.bam} --refFile={input.ref} --output={output} {params.dedup} --minFlank=0 --regions={input.target} --minBaseQual=20 --minMapQual=30 --minVarFreq=0.02
    """

rule vt_platypusGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Platypus/{seq_name}.Platypus.germline.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Platypus/{seq_name}.Platypus.germline.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_PlatypusGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_platypusGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Platypus/{seq_name}.Platypus.germline.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Platypus/{seq_name}.Platypus.germline.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule split_snp_indel_platypusGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Platypus/{seq_name}.Platypus.germline.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/Normal/Platypus/{seq_name}.Platypus.germline.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/Normal/Platypus/{seq_name}.Platypus.germline.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.split_platypusGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/Platypus/{wildcards.seq_name}.Platypus.germline.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/Platypus/{wildcards.seq_name}.Platypus.germline.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/Platypus/{wildcards.seq_name}.Platypus.germline.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/Platypus/{wildcards.seq_name}.Platypus.germline.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/Platypus/{wildcards.seq_name}.Platypus.germline.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/Platypus/{wildcards.seq_name}.Platypus.germline.snv.normalized.vcf
        """

rule piscesGerm :
    input :
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
        dir_ref = genome_dir
    output :
        config["dir"]["base"]+"/{sample}/Normal/Pisces/{seq_name}.Pisces.germline.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.piscesGerm.txt"
    params:
        base_dir=output_dir,
        dedup=dedup_option_pisces
    shell:"""
    dotnet /opt/Pisces/Pisces.dll -bam {input.bam} -g {input.dir_ref} {params.dedup} --gvcf false -i {input.target} -t 8 --minbq 20 --minmq 30 --mindp 10 --minvf 0.02 --callmnvs true --threadbychr true --outfolder {params.base_dir}/{wildcards.sample}/Normal/Pisces
    mv {params.base_dir}/{wildcards.sample}/Normal/Pisces/{wildcards.seq_name}.sort.RG.*.vcf {output}
    """

rule vt_piscesGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Pisces/{seq_name}.Pisces.germline.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Pisces/{seq_name}.Pisces.germline.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_piscesGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_piscesGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Pisces/{seq_name}.Pisces.germline.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Pisces/{seq_name}.Pisces.germline.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule split_snp_indel_piscesGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Pisces/{seq_name}.Pisces.germline.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/Normal/Pisces/{seq_name}.Pisces.germline.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/Normal/Pisces/{seq_name}.Pisces.germline.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.split_piscesGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/Pisces/{wildcards.seq_name}.Pisces.germline.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/Pisces/{wildcards.seq_name}.Pisces.germline.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/Pisces/{wildcards.seq_name}.Pisces.germline.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/Pisces/{wildcards.seq_name}.Pisces.germline.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/Pisces/{wildcards.seq_name}.Pisces.germline.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/Pisces/{wildcards.seq_name}.Pisces.germline.snv.normalized.vcf
        """

#VarScan2 Germline SNV (Germline Analysis)
rule VarScan2_SNPGerm :
    input:
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.snv.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.VarScan2_SNPGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
    # Variant calling with VarScan2
    samtools mpileup \
    -ABQ0 \
    -d 100000 \
    -f {input.ref} \
    -l {input.target} \
    {input.bam} | java -Xmx16G -jar /usr/share/java/VarScan.v2.3.9.jar mpileup2snp \
    --output-vcf 1 \
    --min-coverage 10 \
    --min-reads2 2 \
    --min-avg-qual 20 \
    --min-var-freq 0.02 \
    --strand-filter 0 > {output}
    """

rule vt_varscan2_snp :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.snv.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.snv.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_VarScan2_SNPGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_varscan2_snp :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.snv.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.snv.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule VarScan2_INDELGerm :
    input:
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.indel.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.VarScan2_INDELGerm.txt"
    shell:"""
    # Variant calling with VarScan2
    samtools mpileup \
    -ABQ0 \
    -d 100000 \
    -f {input.ref} \
    -l {input.target} \
    {input.bam} | java -Xmx16G -jar /usr/share/java/VarScan.v2.3.9.jar mpileup2indel \
    --output-vcf 1 \
    --min-coverage 10 \
    --min-reads2 2 \
    --min-avg-qual 20 \
    --min-var-freq 0.02 \
    --strand-filter 0 > {output}
    """

rule vt_varscan2_indel :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.indel.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_VarScan2_INDELGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """   

rule GATK_left_align_varscan2_indel :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.indel.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/VarScan2/{seq_name}.VarScan2.germline.indel.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule StrelkaGerm :
    input:
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.vcf",
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}.StrelkaGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
    #Germline Variant calling with Strelka
    source activate utils
    configureStrelkaGermlineWorkflow.py --exome --bam={input.bam} --referenceFasta={input.ref} --runDir={params.base_dir}/{wildcards.sample}/Normal/Strelka ;
    {params.base_dir}/{wildcards.sample}/Normal/Strelka/runWorkflow.py -m local -j 8 ;
    gunzip -f {params.base_dir}/{wildcards.sample}/Normal/Strelka/results/variants/variants.vcf.gz
    mv {params.base_dir}/{wildcards.sample}/Normal/Strelka/results/variants/variants.vcf {output}
    rm -r {params.base_dir}/{wildcards.sample}/Normal/Strelka/workspace/*
    """

rule StrelkaFilterRegionGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.vcf",
        target=config["metadata"]["design"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.recode.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.StrelkaFilterRegionGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
    vcftools --vcf {input.vcf} --bed {input.target} --recode-INFO-all --recode --out {params.base_dir}/{wildcards.sample}/Normal/Strelka/{wildcards.seq_name}.Strelka.germline
    """

rule vt_strelka :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.recode.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_StrelkaGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_strelka :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.recode.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """


rule split_snp_indel_StrelkaGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/Normal/Strelka/{seq_name}.Strelka.germline.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.split_StrelkaGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/Strelka/{wildcards.seq_name}.Strelka.germline.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/Strelka/{wildcards.seq_name}.Strelka.germline.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/Strelka/{wildcards.seq_name}.Strelka.germline.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/Normal/Strelka/{wildcards.seq_name}.Strelka.germline.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/Normal/Strelka/{wildcards.seq_name}.Strelka.germline.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/Normal/Strelka/{wildcards.seq_name}.Strelka.germline.snv.normalized.vcf
        """

rule ScalpelGerm :
    input :
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"]
    output :
        config["dir"]["base"]+"/{sample}/Normal/Scalpel/{seq_name}.Scalpel.germline.indel.vcf"
    container:
        "docker://lethalfang/scalpel:0.5.4"
    benchmark:
         "benchmarks/{sample}_{seq_name}.ScalpelGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
    /opt/scalpel-0.5.4/scalpel-discovery --single --bam {input.bam} --bed {input.target} --ref {input.ref} --dir {params.base_dir}/{wildcards.sample}/Normal/Scalpel --numprocs 8 --intarget
    /opt/scalpel-0.5.4/scalpel-export --single --db {params.base_dir}/{wildcards.sample}/Normal/Scalpel/variants.db.dir --bed {input.target} --ref {input.ref} --min-alt-count 2 --min-vaf 0.02 --min-coverage 10 --intarget > {output}
    """

rule vt_scalpelGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Scalpel/{seq_name}.Scalpel.germline.indel.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Scalpel/{seq_name}.Scalpel.germline.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_ScalpelGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_scalpelGerm :
    input:
        vcf=config["dir"]["base"]+"/{sample}/Normal/Scalpel/{seq_name}.Scalpel.germline.indel.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/Normal/Scalpel/{seq_name}.Scalpel.germline.indel.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule prepare_pindelGerm :
    input:
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam"
    output:
        temp(config["dir"]["base"]+"/{sample}/Normal/pindel/{seq_name}.pindel.config.txt")
    container:
        "docker://ngsom/tumorseq"
    params:
        insert_size = 200
    shell:
        "echo -e \"{input.bam}\t{params.insert_size}\t{wildcards.seq_name}\" > {output}"

rule pindelGerm :
    input:
        config=config["dir"]["base"]+"/{sample}/Normal/pindel/{seq_name}.pindel.config.txt",
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"]
    output:
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_SI"),
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_D"),
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_LI"),
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_INV"),
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_TD"),
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_BP"),
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_CloseEndMapped"),
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_INT_final"),
        temp(output_dir+"/{sample}/Normal/pindel/tmp/{seq_name}.{chr}.INDEL_RP"),
    benchmark:
         "benchmarks/{sample}_{seq_name}.{chr}.pindelGerm.txt"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:
        """
        pindel -T 4 -f {input.ref} -i {input.config} --chromosome {wildcards.chr} -w 10 -M 5 -o {params.base_dir}/{wildcards.sample}/Normal/pindel/tmp/{wildcards.seq_name}.{wildcards.chr}.INDEL
        """

rule merge_pindel_filesGerm :
    input:
        SI=expand(output_dir+"/{{sample}}/Normal/pindel/tmp/{{seq_name}}.{chr}.INDEL_SI",chr=CHROMS),
        D=expand(output_dir+"/{{sample}}/Normal/pindel/tmp/{{seq_name}}.{chr}.INDEL_D",chr=CHROMS),
        LI=expand(output_dir+"/{{sample}}/Normal/pindel/tmp/{{seq_name}}.{chr}.INDEL_LI",chr=CHROMS),
        INV=expand(output_dir+"/{{sample}}/Normal/pindel/tmp/{{seq_name}}.{chr}.INDEL_INV",chr=CHROMS),
        TD=expand(output_dir+"/{{sample}}/Normal/pindel/tmp/{{seq_name}}.{chr}.INDEL_TD",chr=CHROMS),
        BP=expand(output_dir+"/{{sample}}/Normal/pindel/tmp/{{seq_name}}.{chr}.INDEL_BP",chr=CHROMS),
    output:
        SI=temp(output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_SI"),
        D=temp(output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_D"),
        LI=temp(output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_LI"),
        INV=temp(output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_INV"),
        TD=temp(output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_TD"),
        BP=temp(output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_BP"),
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:
        """
        cat {input.SI} > {output.SI}
        cat {input.D} > {output.D}
        cat {input.LI} > {output.LI}
        cat {input.INV} > {output.INV}
        cat {input.TD} > {output.TD}
        cat {input.BP} > {output.BP}
        """

rule pindel2vcfGerm :
    input:
        SI_file=output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_SI",
        D_file=output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_D",
        LI_file=output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_LI",
        INV_file=output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_INV",
        TD_file=output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_TD",
        BP_file=output_dir+"/{sample}/Normal/pindel/{seq_name}.merge.INDEL_BP",
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/Normal/pindel/{seq_name}.pindel.germline.indel.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.pindel2vcfGerm.txt"
    params:
        base_dir=output_dir,
        genome_version=config["genome"]["version"]
    shell:
        """
        pindel2vcf --pindel_output_root {params.base_dir}/{wildcards.sample}/Normal/pindel/{wildcards.seq_name}.merge.INDEL -r {input.ref} -R {params.genome_version} -d 20101123-v -w 300 -mc 10 -e 5 --het_cutoff 0.10 --hom_cutoff 0.75 -v {output}
        """

rule pindel_filter_region :
    input:
        vcf=output_dir+"/{sample}/Normal/pindel/{seq_name}.pindel.germline.indel.vcf",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
    output:
        output_dir+"/{sample}/Normal/pindel/{seq_name}.pindel.germline.indel.LeftAlign.vcf"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --bed {input.target} --recode-INFO-all --recode --out {params.base_dir}/{wildcards.sample}/Normal/pindel/{wildcards.seq_name}.pindel.germline.indel
        mv {params.base_dir}/{wildcards.sample}/Normal/pindel/{wildcards.seq_name}.pindel.germline.indel.recode.vcf {output}
        """

rule vt_pindelGerm :
    input:
        vcf=output_dir+"/{sample}/Normal/pindel/{seq_name}.pindel.germline.indel.LeftAlign.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/Normal/pindel/{seq_name}.pindel.germline.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.vt_pindelGerm.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule Mutect2Germ:
    input:
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
        gnomad=config["genome"]["gnomad_af_only"]
    output:
        vcf=output_dir+"/{sample}/Normal/Mutect2/{seq_name}.Mutect2.for.pon.vcf.gz"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
         "benchmarks/{sample}_{seq_name}.Mutect2Germ.txt"
    shell:"""
        # Mutect2 Germline
        file_name=$(basename {input.bam})
		name=${{file_name%.sort*}}
        gatk Mutect2 \
        --java-options -Xmx16G \
        --native-pair-hmm-threads 8 \
        -max-mnp-distance 0 \
        --reference {input.ref} \
        -I {input.bam} \
        -tumor $name \
        -germline-resource {input.gnomad} \
        -L {input.target} \
        -O {output.vcf}
        """

#Run MSI analysis
rule msisensor:
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
        microsat=config["metadata"]["microsat"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.msi",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_name}_{normal}.msi.txt"
    params:
        base_dir=config["dir"]["base"]
    shell:
        """
        msisensor2 msi -d {input.microsat} -c 20 -b 8 -n {input.paired[0]} -t {input.paired[1]} -o {output}
	    awk 'BEGIN{{OFS="\t"}} NR==1{{print $0,"SAMPLE"}} NR>1{{print $0,"{wildcards.seq_name}"}}' {output} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.msi.tmp
	    mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.msi.tmp {output}
        """

#VarScan2 Somatic SNV+INDEL
rule VarScan2Somatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        temp(config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.snp.vcf"),
        temp(config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.indel.vcf"),
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.VarScan2Somatic.txt"
    params:
        base_dir=output_dir
    shell:"""
    samtools mpileup -ABQ0 \
    -q 15 \
    -d 100000 \
    -f {input.ref} \
    -l {input.target} \
    {input.paired[1]} {input.paired[0]} | awk '{{if($4 != 0) print $0}}' | awk '{{if($7 != 0) print $0}}' | java -Xmx16G -jar /usr/share/java/VarScan.v2.3.9.jar somatic -mpileup {params.base_dir}/{wildcards.sample}/SomaticAnalysis/VarScan2/{wildcards.seq_name}_vs_{wildcards.normal}.VarScan2.somatic \
    --output-vcf 1 \
    --min-coverage 10 \
    --min-reads2 2 \
    --min-avg-qual 20 \
    --min-var-freq 0.02 \
    --strand-filter 0
    """

rule VarScan2SomaticBreakMulti :
    input:
        snp=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.snp.vcf",
        indel=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.indel.vcf",
    output:
        snp=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.snv.LeftAlign.vcf",
        indel=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.indel.LeftAlign.vcf",
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:"""
    vcflib vcfbreakmulti {input.snp} > {output.snp}
	vcflib vcfbreakmulti {input.indel} > {output.indel}
    """

rule vt_varscan2_somatic_snp :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.snp.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.snv.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_VarScan2Somatic_snp.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule vt_varscan2_somatic_indel :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.indel.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2/{seq_name}_vs_{normal}.VarScan2.somatic.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_VarScan2Somatic_indel.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

#VarScan2 Somatic SNV+INDEL
rule FreeBayesSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.FreeBayesSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
    #Somatic Variant calling with FreeBayes
    freebayes -b {input.paired[0]} -b {input.paired[1]} \
    -v {output} \
    -t {input.target} \
    -f {input.ref} \
    -F 0.02 \
    --min-coverage 10 \
    -C 2 \
    -m 30 \
    -q 20 \
    -R 0 \
    -S 0 \
    --pooled-discrete \
    --pooled-continuous \
    --allele-balance-priors-off
    """

rule FreeBayesSomaticFilter :
    input:
        paired=get_paired_samples,
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.vcf"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.somatic.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.FreeBayesSomaticFilter.txt"
    params:
        base_dir=output_dir
    shell:"""
    #Somatic Filter
    # Filter FreeBayes somatic test
    file_name_normal=$(basename {input.paired[1]})
	seq_name_normal=${{file_name_normal%.sort*}}
    file_name_tumor=$(basename {input.paired[0]})
	seq_name_tumor=${{file_name_tumor%.sort*}}
    workflow/scripts/somatic_freebayes.py {input.vcf} $seq_name_tumor $seq_name_normal > {output}
    """

rule vt_freebayesSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.somatic.vcf",
        ref=config["genome"]["fasta_file"]
    output:
       config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.somatic.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_FreeBayesSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_FreeBayesSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.somatic.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.somatic.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule split_snp_indel_FreeBayesSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.somatic.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.somatic.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/FreeBayes/{seq_name}_vs_{normal}.FreeBayes.somatic.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.split_FreebayesSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/FreeBayes/{wildcards.seq_name}_vs_{wildcards.normal}.FreeBayes.somatic.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/FreeBayes/{wildcards.seq_name}_vs_{wildcards.normal}.FreeBayes.somatic.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/FreeBayes/{wildcards.seq_name}_vs_{wildcards.normal}.FreeBayes.somatic.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/FreeBayes/{wildcards.seq_name}_vs_{wildcards.normal}.FreeBayes.somatic.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/FreeBayes/{wildcards.seq_name}_vs_{wildcards.normal}.FreeBayes.somatic.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/FreeBayes/{wildcards.seq_name}_vs_{wildcards.normal}.FreeBayes.somatic.snv.normalized.vcf
        """

#Mutect1 SNV
rule Mutect:
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
        dbsnp=config["genome"]["known_site"],
        cosmic=config["genome"]["cosmic"]
    output:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect/{seq_name}_vs_{normal}.Mutect.somatic.snv.vcf",
        stats=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect/{seq_name}_vs_{normal}.Mutect.somatic.snv.stats"
    container:
        "docker://ngsom/mutect"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.Mutect.txt"
    params:
        base_dir=output_dir
    shell:"""
        #Somatic Variant calling with Mutect
        java -Xmx16G -jar /usr/share/java/mutect-1.1.7.jar -T MuTect \
        --reference_sequence {input.ref} \
        --cosmic {input.cosmic} \
        --dbsnp {input.dbsnp} \
        --intervals {input.target} \
        -I:tumor {input.paired[0]} \
        -I:normal {input.paired[1]} \
        --out {output.stats} \
        --vcf {output.vcf} \
        --max_alt_allele_in_normal_fraction 0.05 --max_alt_alleles_in_normal_count 5 -dfrac 1 --pir_median_threshold 0
        """

rule vt_Mutect :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect/{seq_name}_vs_{normal}.Mutect.somatic.snv.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect/{seq_name}_vs_{normal}.Mutect.somatic.snv.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_Mutect.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_Mutect :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect/{seq_name}_vs_{normal}.Mutect.somatic.snv.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect/{seq_name}_vs_{normal}.Mutect.somatic.snv.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule SomaticSniper :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        temp(config["dir"]["base"]+"/{sample}/SomaticAnalysis/SomaticSniper/{seq_name}_vs_{normal}.SomaticSniper.somatic.snv.vcf")
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.SomaticSniper.txt"
    params:
        base_dir=output_dir
    shell:"""
    #Somatic Variant calling with SomaticSniper
    bam-somaticsniper -q 1 -Q 10 -G -L -F vcf -f {input.ref} {input.paired[0]} {input.paired[1]} {output}
    """

rule SomaticSniperFilterRegion :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/SomaticSniper/{seq_name}_vs_{normal}.SomaticSniper.somatic.snv.vcf",
        target=config["metadata"]["design"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/SomaticSniper/{seq_name}_vs_{normal}.SomaticSniper.somatic.snv.recode.vcf"
    container:
        "docker://ngsom/somatic"
    params:
        base_dir=output_dir
    shell:"""
    # keep variant in region
    vcftools --vcf {input.vcf} --bed {input.target} --recode-INFO-all --recode --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/SomaticSniper/{wildcards.seq_name}_vs_{wildcards.normal}.SomaticSniper.somatic.snv
    """

rule vt_SomaticSniper :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/SomaticSniper/{seq_name}_vs_{normal}.SomaticSniper.somatic.snv.recode.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/SomaticSniper/{seq_name}_vs_{normal}.SomaticSniper.somatic.snv.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_SomaticSniper.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule SomaticSniperBreakMulti :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/SomaticSniper/{seq_name}_vs_{normal}.SomaticSniper.somatic.snv.recode.vcf"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/SomaticSniper/{seq_name}_vs_{normal}.SomaticSniper.somatic.snv.LeftAlign.vcf"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:"""
    vcflib vcfbreakmulti {input.vcf} > {output}
    """

rule LoFreqSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        snp=config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.snv.vcf",
        indel=config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.indel.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.Lofreq.txt"
    params:
        base_dir=output_dir
    shell:"""
    #Somatic Variant calling with LoFreq
    lofreq indelqual --dindel --ref {input.ref} -o {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.normal.dindel.bam {input.paired[1]}
	lofreq indelqual --dindel --ref {input.ref} -o {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.tumor.dindel.bam {input.paired[0]}
	samtools index {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.normal.dindel.bam
	samtools index {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.tumor.dindel.bam
    lofreq somatic --call-indels -n {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.normal.dindel.bam -t {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.tumor.dindel.bam -f {input.ref} --threads 8 -l {input.target} -o {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}_vs_{wildcards.normal}.LoFreq.
    gunzip -f {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}_vs_{wildcards.normal}.LoFreq.somatic_final.snvs.vcf.gz
    gunzip -f {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}_vs_{wildcards.normal}.LoFreq.somatic_final.indels.vcf.gz
    mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}_vs_{wildcards.normal}.LoFreq.somatic_final.snvs.vcf {output.snp}
    mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}_vs_{wildcards.normal}.LoFreq.somatic_final.indels.vcf {output.indel}
    rm {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.normal.dindel.bam
    rm {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.tumor.dindel.bam
    rm {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.normal.dindel.bam.bai
    rm {params.base_dir}/{wildcards.sample}/SomaticAnalysis/LoFreq/{wildcards.seq_name}.tumor.dindel.bam.bai
    """

rule vt_LoFreqSomatic_snp :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.snv.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.snv.normalized.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_snp_Lofreq.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule vt_LoFreqSomatic_indel :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.indel.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.indel.normalized.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}vt_indel_Lofreq.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_LoFreqSomatic :
    input:
        snp=config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.snv.vcf",
        indel=config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.indel.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        snp=config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.snv.LeftAlign.vcf",
        indel=config["dir"]["base"]+"/{sample}/SomaticAnalysis/LoFreq/{seq_name}_vs_{normal}.LoFreq.somatic.indel.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.snp} \
        --split-multi-allelics \
        --O {output.snp}
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.indel} \
        --split-multi-allelics \
        --O {output.indel}
        """

rule MuseSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
        dbsnp=config["genome"]["known_site"]
    output:
        txt=temp(config["dir"]["base"]+"/{sample}/SomaticAnalysis/Muse/{seq_name}_vs_{normal}.MuSE.txt"),
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Muse/{seq_name}_vs_{normal}.Muse.somatic.snv.vcf"
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.MuseSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
    #Somatic Variant calling with Muse
    awk '{{print $1":"$2"-"$3}}' {input.target} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Muse/{wildcards.seq_name}.region_muse.bed
	MuSE call -O {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Muse/{wildcards.seq_name}_vs_{wildcards.normal} -f {input.ref} -l {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Muse/{wildcards.seq_name}.region_muse.bed {input.paired[0]} {input.paired[1]}
	MuSE sump -I {output.txt} -E -O {output.vcf} -D {input.dbsnp}
    rm {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Muse/{wildcards.seq_name}.region_muse.bed
    """

rule vt_MuseSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Muse/{seq_name}_vs_{normal}.Muse.somatic.snv.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Muse/{seq_name}_vs_{normal}.Muse.somatic.snv.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_MuseSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_MuseSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Muse/{seq_name}_vs_{normal}.Muse.somatic.snv.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Muse/{seq_name}_vs_{normal}.Muse.somatic.snv.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule StrelkaSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Strelka/{seq_name}_vs_{normal}.Strelka.somatic.snv.LeftAlign.vcf",
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Strelka/{seq_name}_vs_{normal}.Strelka.somatic.indel.LeftAlign.vcf"
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.StrelkaSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
    #Somatic Variant calling with Strelka
    source activate utils
    configureStrelkaSomaticWorkflow.py --exome --normal={input.paired[1]} --tumor={input.paired[0]} --ref={input.ref} --runDir={params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_tmp --callRegions {input.target}.gz
    {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_tmp/runWorkflow.py -m local -j 8 ;
    gunzip {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_tmp/results/variants/*.gz ;
    rm {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_tmp/results/variants/*.gz.tbi ;
    vcftools --vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_tmp/results/variants/somatic.snvs.vcf --bed {input.target} --recode-INFO-all  --recode --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_vs_{wildcards.normal}.Strelka.somatic.snv ;
    mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_vs_{wildcards.normal}.Strelka.somatic.snv.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_vs_{wildcards.normal}.Strelka.somatic.snv.LeftAlign.vcf ;
    vcftools --vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_tmp/results/variants/somatic.indels.vcf --bed {input.target} --recode-INFO-all --recode --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_vs_{wildcards.normal}.Strelka.somatic.indel ;
    mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_vs_{wildcards.normal}.Strelka.somatic.indel.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_vs_{wildcards.normal}.Strelka.somatic.indel.LeftAlign.vcf ;
    rm -r {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Strelka/{wildcards.seq_name}_tmp
    """

rule vt_StrelkaSomatic_snp :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Strelka/{seq_name}_vs_{normal}.Strelka.somatic.snv.LeftAlign.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Strelka/{seq_name}_vs_{normal}.Strelka.somatic.snv.normalized.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_snp_StrelkaSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule vt_StrelkaSomatic_indel :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Strelka/{seq_name}_vs_{normal}.Strelka.somatic.indel.LeftAlign.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Strelka/{seq_name}_vs_{normal}.Strelka.somatic.indel.normalized.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_indel_StrelkaSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

if create_pon is True :

    rule CreatePONForMutect2:
        input: 
            vcfs=expand(config["dir"]["base"]+"/{sample}/Normal/Mutect2/{seq_name}.Mutect2.for.pon.vcf.gz",zip,sample=samples["samples"][samples["type"]=="Normal"],seq_name=SAMPLES_NORMAL),
            ref=config["genome"]["fasta_file"],
            target=config["metadata"]["design"],
        output:
            output_dir+"/pon.vcf.gz",
            directory(putput_dir+"/pon_db")
        container:
            "docker://broadinstitute/gatk:4.2.2.0"
        params:
             base_dir=output_dir,
             gatk_input=lambda wc, input: " ".join(['-V %s' % x for x in input.vcfs])
        shell:"""
            gatk GenomicsDBImport \
            --java-options -Xmx72G \
            -R {input.ref} \
            -L {input.target} \
            --genomicsdb-workspace-path {params.base_dir}/pon_db \
            {params.gatk_input} \
            --merge-input-intervals true

            cd {params.base_dir}
            gatk CreateSomaticPanelOfNormals \
            --java-options -Xmx72G \
            -R {input.ref} -V gendb://pon_db \
            -O {output}

        """    

rule Mutect2TumorOnly:
    input:
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
        gnomad=config["genome"]["gnomad_af_only"],
        pon=config["mutect2"]["pon"] if not create_pon else config["dir"]["base"]+"/pon.vcf.gz"
    output:
        vcf=output_dir+"/{sample}/{seq_type}/Mutect2/{seq_name}.Mutect2.tumor_only.unfiltered.vcf",
        f1r2=output_dir+"/{sample}/{seq_type}/Mutect2/{seq_name}.Mutect2.tumor_only.f1r2.tar.gz"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
         "benchmarks/{sample}_{seq_type}_{seq_name}.Mutect2TumorOnly.txt"
    shell:"""
        # Mutect2 Tumor Only
        file_name=$(basename {input.bam})
		name=${{file_name%.sort*}}
        gatk Mutect2 \
        --java-options -Xmx16G \
        --native-pair-hmm-threads 8 \
        -max-mnp-distance 0 \
        --reference {input.ref} \
        -I {input.bam} \
        -tumor $name \
        -germline-resource {input.gnomad} \
        -pon {input.pon} \
        -L {input.target} \
        --f1r2-tar-gz {output.f1r2} \
        -O {output.vcf}
        """

#Mutect2 SNV + INDEL GATK 4.2
rule LearnReadOrientationModelTumorOnly:
    input:
        f1r2=config["dir"]["base"]+"/{sample}/{seq_type}/Mutect2/{seq_name}.Mutect2.tumor_only.f1r2.tar.gz"
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/Mutect2/{seq_name}.tumor_only.read-orientation-model.tar.gz"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir,
    shell:"""
        gatk LearnReadOrientationModel \
        --java-options -Xmx16G \
        -I {input.f1r2} \
        -O {output}
		"""

#Mutect2 SNV + INDEL GATK 4.2
rule FilterMutect2TumorOnly:
    input:
        model=config["dir"]["base"]+"/{sample}/{seq_type}/Mutect2/{seq_name}.tumor_only.read-orientation-model.tar.gz",
        vcf=config["dir"]["base"]+"/{sample}/{seq_type}/Mutect2/{seq_name}.Mutect2.tumor_only.unfiltered.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        vcf=config["dir"]["base"]+"/{sample}/{seq_type}/Mutect2/{seq_name}.Mutect2.tumor_only.filtered.vcf",
        stats=config["dir"]["base"]+"/{sample}/{seq_type}/Mutect2/{seq_name}.Mutect2.filtering.stats"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir,
    shell:"""
        gatk FilterMutectCalls \
        --java-options -Xmx16G \
        -R {input.ref} \
        -V {input.vcf} \
        --ob-priors {input.model} \
        --filtering-stats {output.stats} \
        -O {output.vcf}
		 """


#Mutect2 SNV + INDEL GATK 4.2
rule Mutect2Somatic:
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
        gnomad=config["genome"]["gnomad_af_only"],
        pon=config["mutect2"]["pon"] if not create_pon else config["dir"]["base"]+"/pon.vcf.gz"
    output:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.unfiltered.vcf",
        f1r2=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.f1r2.tar.gz"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
        "benchmarks/{sample}_{seq_name}_{normal}.Mutect2Somatic.txt" 
    shell:"""
        # Mutect2 Somatic
        file_name=$(basename {input.paired[1]})
		name=${{file_name%.sort*}}
        gatk Mutect2 \
        --java-options -Xmx16G \
        --native-pair-hmm-threads 8 \
        --reference {input.ref} \
        -I {input.paired[0]} \
        -I {input.paired[1]} \
        -normal $name \
        --germline-resource {input.gnomad} \
        --genotype-germline-sites true \
        --genotype-pon-sites true \
        --interval-padding 50 \
        -pon {input.pon} \
        -L {input.target} \
        --f1r2-tar-gz {output.f1r2} \
        -O {output.vcf}
        """

#Mutect2 SNV + INDEL GATK 4.2
rule LearnReadOrientationModel:
    input:
        f1r2=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.f1r2.tar.gz"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.read-orientation-model.tar.gz"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir,
    shell:"""
        gatk LearnReadOrientationModel \
        --java-options -Xmx16G \
        -I {input.f1r2} \
        -O {output}
		"""

#Mutect2 SNV + INDEL GATK 4.2
rule FilterMutect2:
    input:
        model=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.read-orientation-model.tar.gz",
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.unfiltered.vcf",
        cont_table=config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.CalculateContamination.table",
        ref=config["genome"]["fasta_file"]
    output:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.filtered.vcf",
        stats=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.filtering.stats"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir,
    shell:"""
        gatk FilterMutectCalls \
        --java-options -Xmx16G \
        -R {input.ref} \
        -V {input.vcf} \
        --ob-priors {input.model} \
        --filtering-stats {output.stats} \
        -O {output.vcf}
		 """

rule vt_Mutect2 :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.filtered.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.filtered.normalized.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_Mutect2.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_Mutect2 :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.filtered.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.filtered.LeftAlign.vcf",
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule Funcotator_mutect2_somatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.filtered.LeftAlign.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Funcotator/{seq_name}_vs_{normal}.variants.funcotated.maf",
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Funcotator vcf to maf
        gatk Funcotator \
        --variant {input.vcf} \
        --reference {input.ref} \
        --ref-version hg38 \
        --data-sources-path /shared/projects/pmngs/funcotator_dataSources.v1.7.20200521s \
        --output {output} \
        --output-file-format MAF
        """


rule split_snp_indel_Mutect2 :
    input:
        ref=config["genome"]["fasta_file"],
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.filtered.normalized.vcf"
    output:
        snp=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.snv.normalized.vcf",
        indel=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.indel.normalized.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.split_Mutect2.txt"
    params:
        base_dir=output_dir
    shell:"""
    gatk SelectVariants --java-options -Xmx16G -R {input.ref} -V {input.vcf} --select-type-to-include SNP -O {output.snp}
	gatk SelectVariants --java-options -Xmx16G -R {input.ref} -V {input.vcf} --select-type-to-include INDEL --select-type-to-include MNP -O {output.indel}
    """

rule VarDictSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarDict/{seq_name}_vs_{normal}.VarDict.somatic.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.VarDictSomatic.txt"
    params:
        base_dir=output_dir,
        dedup=dedup_option_vardict
    shell:"""
    VarDict {params.dedup} -th 8 -G {input.ref} -f 0.02 -N {wildcards.seq_name} -r 3 -b "{input.paired[0]}|{input.paired[1]}" -c 1 -S 2 -E 3 -g 4 {input.target} | testsomatic.R | var2vcf_paired.pl -N "{wildcards.seq_name}|{wildcards.normal}" -f 0.02 > {output}
    """

rule vt_VarDictSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarDict/{seq_name}_vs_{normal}.VarDict.somatic.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarDict/{seq_name}_vs_{normal}.VarDict.somatic.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_VarDictSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_VarDict :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarDict/{seq_name}_vs_{normal}.VarDict.somatic.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarDict/{seq_name}_vs_{normal}.VarDict.somatic.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule split_snp_indel_VarDict :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarDict/{seq_name}_vs_{normal}.VarDict.somatic.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarDict/{seq_name}_vs_{normal}.VarDict.somatic.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarDict/{seq_name}_vs_{normal}.VarDict.somatic.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.split_VarDictSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/VarDict/{wildcards.seq_name}_vs_{wildcards.normal}.VarDict.somatic.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/VarDict/{wildcards.seq_name}_vs_{wildcards.normal}.VarDict.somatic.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/VarDict/{wildcards.seq_name}_vs_{wildcards.normal}.VarDict.somatic.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/VarDict/{wildcards.seq_name}_vs_{wildcards.normal}.VarDict.somatic.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/VarDict/{wildcards.seq_name}_vs_{wildcards.normal}.VarDict.somatic.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/VarDict/{wildcards.seq_name}_vs_{wildcards.normal}.VarDict.somatic.snv.normalized.vcf
        """

rule prepare_pindel_somatic :
    input:
        paired=get_filter_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.pindel.config.txt"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir,
        insert_size=200
    shell:"""
    echo -e \"{input.paired[0]}\t{params.insert_size}\tTUMOR\n{input.paired[1]}\t{params.insert_size}\tNORMAL\" > {output}
    """

rule prepare_pindel_somatic_filter :
    input:
        paired=get_filter_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
        head=output_dir+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.merge.INDEL.head"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.pindel.config.somatic.txt"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir,
    shell:"""
    echo -e \"indel.filter.input={input.head}\nindel.filter.vaf = 0.02 \nindel.filter.cov = 20\nindel.filter.hom = 6\nindel.filter.pindel2vcf = /opt/pindel/pindel2vcf4tcga\nindel.filter.reference = {input.ref}\nindel.filtered.referencename = GRCh38\nindel.filter.referencedate = 22-01-24\nindel.filter.output = {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}_vs_{wildcards.normal}.INDEL.pindel.somatic.vcf\" > {output}
    """

rule pindel_somatic :
    input:
        config=config["dir"]["base"]+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.pindel.config.txt",
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_SI",
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_D",
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_LI",
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_INV",
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_TD",
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_BP",
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_CloseEndMapped",
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_INT_final",
        output_dir+"/{sample}/SomaticAnalysis/pindel/tmp/{seq_name}_vs_{normal}.{chr}.INDEL_RP",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.{chr}.pindel_somatic.txt"
    params:
        base_dir=output_dir
    shell:
        """
        pindel -T 4 -f {input.ref} -i {input.config} --chromosome {wildcards.chr} -w 10 -M 5 -o {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/tmp/{wildcards.seq_name}_vs_{wildcards.normal}.{wildcards.chr}.INDEL
        """

rule merge_pindel_filesSomatic :
    input:
        SI=expand(output_dir+"/{{sample}}/SomaticAnalysis/pindel/tmp/{{seq_name}}_vs_{{normal}}.{chr}.INDEL_SI",chr=CHROMS),
        D=expand(output_dir+"/{{sample}}/SomaticAnalysis/pindel/tmp/{{seq_name}}_vs_{{normal}}.{chr}.INDEL_D",chr=CHROMS),
        LI=expand(output_dir+"/{{sample}}/SomaticAnalysis/pindel/tmp/{{seq_name}}_vs_{{normal}}.{chr}.INDEL_LI",chr=CHROMS),
        INV=expand(output_dir+"/{{sample}}/SomaticAnalysis/pindel/tmp/{{seq_name}}_vs_{{normal}}.{chr}.INDEL_INV",chr=CHROMS),
        TD=expand(output_dir+"/{{sample}}/SomaticAnalysis/pindel/tmp/{{seq_name}}_vs_{{normal}}.{chr}.INDEL_TD",chr=CHROMS),
        BP=expand(output_dir+"/{{sample}}/SomaticAnalysis/pindel/tmp/{{seq_name}}_vs_{{normal}}.{chr}.INDEL_BP",chr=CHROMS),
    output:
        output_dir+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.merge.INDEL.head"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:
        """
        grep ChrID {input.SI} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}.merge.INDEL_SI.head
        grep ChrID {input.D} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}.merge.INDEL_D.head
        grep ChrID {input.LI} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}.merge.INDEL_LI.head
        grep ChrID {input.INV} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}.merge.INDEL_INV.head
        grep ChrID {input.TD} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}.merge.INDEL_TD.head
        grep ChrID {input.BP} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}.merge.INDEL_BP.head
        cat {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}.merge.*.head > {output}
        """

rule pindelFilterSomatic :
    input:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.pindel.config.somatic.txt"
    output:
        output_dir+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.INDEL.pindel.somatic.vcf",
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:
        """
        perl /opt/pindel/somatic_filter/somatic_indelfilter.pl {input}
        """

rule pindelSomaticFilterRegion :
    input:
        vcf=output_dir+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.INDEL.pindel.somatic.vcf",
        target=config["metadata"]["design"]
    output:
        output_dir+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.pindel.somatic.indel.LeftAlign.vcf",
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:"""
    # keep variant in region
    vcftools --vcf {input.vcf} --bed {input.target} --recode-INFO-all --recode --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}_vs_{wildcards.normal}.pindel.somatic.indel
    mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/pindel/{wildcards.seq_name}_vs_{wildcards.normal}.pindel.somatic.indel.recode.vcf {output}
    """

rule vt_pindelSomatic :
    input:
        vcf=output_dir+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.pindel.somatic.indel.LeftAlign.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/SomaticAnalysis/pindel/{seq_name}_vs_{normal}.pindel.somatic.indel.normalized.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_pindel_somatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule ScalpelSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Scalpel/{seq_name}_vs_{normal}.Scalpel.somatic.indel.LeftAlign.vcf"
    container:
        "docker://lethalfang/scalpel:0.5.4"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.ScalpelSomatic.txt"
    params:
        base_dir=output_dir,
        dedup=dedup_option_vardict
    shell:"""
    /opt/scalpel-0.5.4/scalpel-discovery --somatic --normal {input.paired[1]} --tumor {input.paired[0]} --bed {input.target} --ref {input.ref} --dir {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Scalpel/{wildcards.seq_name}_tmp --numprocs 8 --intarget
    /opt/scalpel-0.5.4/scalpel-export --somatic --db  {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Scalpel/{wildcards.seq_name}_tmp/main/somatic.db.dir --bed {input.target} --ref {input.ref} --min-alt-count-tumor 2 --min-vaf-tumor 0.02 --min-coverage-tumor 10 --intarget >  {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Scalpel/{wildcards.seq_name}_vs_{wildcards.normal}.Scalpel.somatic.indel.vcf
    mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Scalpel/{wildcards.seq_name}_vs_{wildcards.normal}.Scalpel.somatic.indel.vcf {output}
    rm -r {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Scalpel/{wildcards.seq_name}_tmp
    """

rule vt_ScalpelSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Scalpel/{seq_name}_vs_{normal}.Scalpel.somatic.indel.LeftAlign.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Scalpel/{seq_name}_vs_{normal}.Scalpel.somatic.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_ScalpelSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule SeuratSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Seurat/{seq_name}_vs_{normal}.Seurat.somatic.vcf"
    container:
        "docker://ngsom/mutect"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.SeuratSomatic.txt"
    params:
        base_dir=output_dir,
        dedup=dedup_option_vardict
    shell:"""
    java -jar /usr/share/java/Seurat-2.5.jar -T Seurat \
    -R {input.ref} \
    -I:dna_normal {input.paired[1]} \
    -I:dna_tumor {input.paired[0]} \
    -L {input.target} \
    --indels \
    -Q 15 \
    -insert_size 200 \
    -mmq 15 \
    -mbq 20 \
    -mcv 6 \
    -mm 3 \
    -o {output} \
    -go tmp.txt
    """

rule vt_SeuratSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Seurat/{seq_name}_vs_{normal}.Seurat.somatic.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Seurat/{seq_name}_vs_{normal}.Seurat.somatic.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_SeuratSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_SeuratSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Seurat/{seq_name}_vs_{normal}.Seurat.somatic.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Seurat/{seq_name}_vs_{normal}.Seurat.somatic.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule split_snp_indel_SeuratSomatic :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Seurat/{seq_name}_vs_{normal}.Seurat.somatic.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Seurat/{seq_name}_vs_{normal}.Seurat.somatic.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Seurat/{seq_name}_vs_{normal}.Seurat.somatic.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.split_SeuratSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Seurat/{wildcards.seq_name}_vs_{wildcards.normal}.Seurat.somatic.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Seurat/{wildcards.seq_name}_vs_{wildcards.normal}.Seurat.somatic.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Seurat/{wildcards.seq_name}_vs_{wildcards.normal}.Seurat.somatic.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Seurat/{wildcards.seq_name}_vs_{wildcards.normal}.Seurat.somatic.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Seurat/{wildcards.seq_name}_vs_{wildcards.normal}.Seurat.somatic.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Seurat/{wildcards.seq_name}_vs_{wildcards.normal}.Seurat.somatic.snv.normalized.vcf
        """

rule LancetSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Lancet/{seq_name}_vs_{normal}.Lancet.somatic.vcf"
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.LancetSomatic.txt"
    params:
        base_dir=output_dir,
        dedup=dedup_option_vardict
    shell:"""
    /opt/lancet/lancet \
    --tumor {input.paired[0]} \
    --normal {input.paired[1]} \
    --ref {input.ref} \
    --min-alt-count-tumor 3 \
    --max-alt-count-normal 1 \
    --min-vaf-tumor 0.02 \
    --max-vaf-normal 0.01 \
    --min-coverage-tumor 4 \
    --min-coverage-normal 10 \
    --bed {input.target} \
    --num-threads 24 > {output}
    """

rule vt_Lancet :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Lancet/{seq_name}_vs_{normal}.Lancet.somatic.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Lancet/{seq_name}_vs_{normal}.Lancet.somatic.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_LancetSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_Lancet :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Lancet/{seq_name}_vs_{normal}.Lancet.somatic.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Lancet/{seq_name}_vs_{normal}.Lancet.somatic.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """

rule split_snp_indel_Lancet :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Lancet/{seq_name}_vs_{normal}.Lancet.somatic.normalized.vcf"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Lancet/{seq_name}_vs_{normal}.Lancet.somatic.snv.normalized.vcf",
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Lancet/{seq_name}_vs_{normal}.Lancet.somatic.indel.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.split_LancetSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        vcftools --vcf {input.vcf} --keep-only-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Lancet/{wildcards.seq_name}_vs_{wildcards.normal}.Lancet.somatic.indel.normalized
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Lancet/{wildcards.seq_name}_vs_{wildcards.normal}.Lancet.somatic.indel.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Lancet/{wildcards.seq_name}_vs_{wildcards.normal}.Lancet.somatic.indel.normalized.vcf
        vcftools --vcf {input.vcf} --remove-indels --recode --recode-INFO-all --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Lancet/{wildcards.seq_name}_vs_{wildcards.normal}.Lancet.somatic.snv.normalized
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Lancet/{wildcards.seq_name}_vs_{wildcards.normal}.Lancet.somatic.snv.normalized.recode.vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Lancet/{wildcards.seq_name}_vs_{wildcards.normal}.Lancet.somatic.snv.normalized.vcf
        """

rule VirmidSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Virmid/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall.bam"+".virmid.som.passed.vcf"
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}.VirmidSomatic.txt"
    params:
        base_dir=output_dir,
        dedup=dedup_option_vardict
    shell:"""
    java -jar /opt/virmid-1.1.0/Virmid.jar \
    -R {input.ref} \
    -D {input.paired[0]} \
    -N {input.paired[1]} \
    -w {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Virmid \
    -r 150 \
    -t 8 \
    -c1 10 \
    -C1 1000 \
    -c2 10 \
    -C2 1000 \
    -o {wildcards.seq_name}
    """

rule VirmidSomaticFilterRegion :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Virmid/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall.bam"+".virmid.som.passed.vcf",
        target=config["metadata"]["design"]
    output:
        output_dir+"/{sample}/SomaticAnalysis/Virmid/{seq_name}_vs_{normal}.Virmid.somatic.snv.LeftAlign.vcf",
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:"""
    # keep variant in region
    grep -v "##INFO=" {input.vcf} > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Virmid/{wildcards.seq_name}.tmp.vcf
    vcftools --vcf {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Virmid/{wildcards.seq_name}.tmp.vcf --bed {input.target} --recode-INFO-all --recode --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Virmid/{wildcards.seq_name}_vs_{wildcards.normal}.Virmid.somatic.snv
    mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Virmid/{wildcards.seq_name}_vs_{wildcards.normal}.Virmid.somatic.snv.recode.vcf {output}
    """

rule vt_VirmidSomatic :
    input:
        vcf=output_dir+"/{sample}/SomaticAnalysis/Virmid/{seq_name}_vs_{normal}.Virmid.somatic.snv.LeftAlign.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/SomaticAnalysis/Virmid/{seq_name}_vs_{normal}.Virmid.somatic.snv.normalized.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_VirmidSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule ShimmerSomatic :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Shimmer/{seq_name}/somatic_diffs.vcf"
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}.ShimmerSomatic.txt"
    params:
        base_dir=output_dir,
        dedup=dedup_option_vardict
    shell:"""
    shimmer.pl \
    --bedfile {input.target} \
    --ref {input.ref} \
    --minqual 15 \
    --mapqual 10 \
    --max_q 0.25 \
    --outdir {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Shimmer/{wildcards.seq_name} \
    {input.paired[1]} \
    {input.paired[0]}
    """

rule vt_Shimmer :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Shimmer/{seq_name}/somatic_diffs.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Shimmer/{seq_name}_vs_{normal}.Shimmer.somatic.snv.normalized.vcf"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.vt_ShimmerSomatic.txt"
    params:
        base_dir=output_dir
    shell:"""
        /opt/vt/vt decompose -s {input.vcf} | /opt/vt/vt normalize -n -r {input.ref} - > {output}
        """

rule GATK_left_align_Shimmer :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Shimmer/{seq_name}/somatic_diffs.vcf",
        ref=config["genome"]["fasta_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Shimmer/{seq_name}_vs_{normal}.Shimmer.somatic.snv.LeftAlign.vcf"
    container:
        "docker://broadinstitute/gatk:4.2.2.0"
    params:
        base_dir=output_dir
    shell:"""
        # Left Align
        gatk LeftAlignAndTrimVariants \
        --java-options -Xmx16G \
        --reference {input.ref} \
        --variant {input.vcf} \
        --split-multi-allelics \
        --O {output}
        """


#Merge vcf SNP Germline
rule merge_snv_caller_germline :
    input:
        input_files=input_germline_snv
    output:
        output_dir+"/{sample}/Normal/{seq_name}.germline.snv.merge.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.merge_snv_caller_germline.txt"
    params:
        base_dir=output_dir,
        args=input_germline_snv_params,
        n=n_concordant_germline_snv
    shell:
        """
        source activate utils
        workflow/scripts/merge_caller_germline.py {params.args} -N {params.n} {output}
        """

rule merge_indel_caller_germline :
    input:
        input_files=input_germline_indel
    output:
        output_dir+"/{sample}/Normal/{seq_name}.germline.indel.merge.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.merge_indel_caller_germline.txt"
    params:
        base_dir=output_dir,
        args=input_germline_indel_params,
        n=n_concordant_germline_indel
    shell:
        """
        source activate utils
        workflow/scripts/merge_caller_indel_germline.py {params.args} -N {params.n} {output}
        """

#Merge vcf SNP Germline
rule merge_snv_caller_somatic :
    input:
        input_files=input_somatic_snv
    output:
        output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.snv.merge.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.merge_snv_caller_somatic.txt"
    params:
        base_dir=output_dir,
        args=input_somatic_snv_params,
        n=n_concordant_somatic_snv
    shell:
        """
        source activate utils
        workflow/scripts/merge_caller_somatic.py {params.args} --tumor {wildcards.seq_name} --normal {wildcards.normal} -N {params.n} {output}
        """

rule merge_indel_caller_somatic :
    input:
        input_files=input_somatic_indel
    output:
        output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.indel.merge.vcf",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.merge_indel_caller_somatic.txt"
    params:
        base_dir=output_dir,
        args=input_somatic_indel_params,
        n=n_concordant_somatic_indel
    shell:
        """
        source activate utils
        workflow/scripts/merge_caller_somatic_indel.py {params.args} --tumor {wildcards.seq_name} --normal {wildcards.normal} -N {params.n} {output}
        """

rule filter_snv_germline :
    input:
        vcf=output_dir+"/{sample}/Normal/{seq_name}.germline.snv.merge.vcf",
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/Normal/{seq_name}.germline.snv.merge.filtered.vcf",
        output_dir+"/{sample}/Normal/{seq_name}.germline.snv.merge.stats"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.filter_snv_germline.txt"
    params:
        base_dir=output_dir
    shell:
        """
        source activate utils
        workflow/scripts/filter_vcf.py -p 8 -f none {input.vcf} {input.bam} {input.ref} {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.snv.merge
        """

rule filter_indel_germline :
    input:
        vcf=output_dir+"/{sample}/Normal/{seq_name}.germline.indel.merge.vcf",
        index=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/Normal/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/Normal/{seq_name}.germline.indel.merge.filtered.vcf",
        output_dir+"/{sample}/Normal/{seq_name}.germline.indel.merge.stats"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}.filter_indel_germline.txt"
    params:
        base_dir=output_dir
    shell:
        """
        source activate utils
        workflow/scripts/filter_vcf.py -p 8 -f none {input.vcf} {input.bam} {input.ref} {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.indel.merge
        """

rule filter_snv_somatic :
    input:
        vcf=output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.snv.merge.vcf",
        bam=get_tumor_bam,
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.snv.merge.filtered.vcf",
        output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.snv.merge.stats"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.filter_snv_somatic.txt"
    params:
        base_dir=output_dir
    shell:
        """
        source activate utils
        workflow/scripts/filter_vcf.py -p 8 -f none {input.vcf} {input.bam[0]} {input.ref} {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.snv.merge
        """

rule filter_indel_somatic :
    input:
        vcf=output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.indel.merge.vcf",
        bam=get_tumor_bam,
        ref=config["genome"]["fasta_file"]
    output:
        output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.indel.merge.filtered.vcf",
        output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.indel.merge.stats"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.filter_indel_somatic.txt"
    params:
        base_dir=output_dir
    shell:
        """
        source activate utils
        workflow/scripts/filter_vcf.py -p 8 -f none {input.vcf} {input.bam[0]} {input.ref} {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.indel.merge
        """

#SAllelic copy number estimation with Sequenza
rule bam2seqz :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
        gc=config["genome"]["gc_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Sequenza/{seq_name}_vs_{normal}.seqz.gz"
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.bam2seqz"
    params:
        base_dir=output_dir,
    shell:"""
    sequenza-utils bam2seqz \
    -n {input.paired[1]} \
    -t {input.paired[0]} \
    --fasta {input.ref} \
    -gc {input.gc} \
    -o {output} \
    --chromosome chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX
    """

rule seqz_binning :
    input:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Sequenza/{seq_name}_vs_{normal}.seqz.gz"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Sequenza/{seq_name}_vs_{normal}.seqz.bin50.gz"
    container:
        "docker://ngsom/somatic"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.seqz_binning"
    params:
        base_dir=output_dir,
    shell:"""
    sequenza-utils seqz_binning --seqz {input} -w 50 -o {output}
    """

rule sequenza :
    input:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Sequenza/{seq_name}_vs_{normal}.seqz.bin50.gz"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Sequenza/{seq_name}_vs_{normal}.seqz.bin50.gz_segments.txt"
    container:
        "docker://ngsom/bioconductor"
    benchmark:
         "benchmarks/{sample}_{seq_name}_{normal}.sequenza"
    params:
        base_dir=output_dir,
    shell:"""
    workflow/scripts/sequenza.R {input} {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Sequenza
    """

rule IntervalFilePureCN :
    input:
        target=config["metadata"]["design"],
        ref=config["genome"]["fasta_file"],
        mappability=config["PureCN"]["mappability"]
    output:
        outfile=config["dir"]["base"]+"/baits_interval.txt",
        export=config["dir"]["base"]+"/baits_optimized.bed"
    container:
        "docker://ngsom/bioconductor"
    params:
        base_dir=output_dir,
        genome_version=config["genome"]["version"]
    shell:"""
    Rscript /usr/local/lib/R/site-library/PureCN/extdata/IntervalFile.R \
    --in-file {input.target} \
    --fasta {input.ref} \
    --out-file {output.outfile} \
    --genome {params.genome_version} \
    --export {output.export} \
    --mappability {input.mappability}
    """

rule CoveragePureCN :
    input:
        interval=config["dir"]["base"]+"/baits_interval.txt",
        ref=config["genome"]["fasta_file"],
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/PureCN/{seq_name}.sort.RG.dedup.recall_coverage_loess.txt.gz"
    container:
        "docker://ngsom/bioconductor"
    params:
        base_dir=output_dir,
    shell:"""
    mkdir {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/PureCN
    Rscript /usr/local/lib/R/site-library/PureCN/extdata/Coverage.R \
    --out-dir {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/PureCN \
    --bam {input.bam} \
    --intervals {input.interval}
    """

if create_normal_db is True :


    rule CreateNormalVCF:
        input: 
            pon=config["mutect2"]["pon"] if not create_pon else config["dir"]["base"]+"/pon.vcf.gz",
            ref=config["genome"]["fasta_file"],
            target=config["metadata"]["design"],
        output:
            output_dir+"/normals.vcf.gz"
        container:
            "docker://broadinstitute/gatk:4.2.2.0"
        params:
             base_dir=output_dir
        shell:"""
            cd {params.base_dir}
            gatk SelectVariants \
            -R {input.ref} \
            -V gendb://pon_db \
            -O {params.base_dir}/normals.vcf
            bgzip -c normals.vcf > normals.vcf.gz
            tabix -p vcf normals.vcf.gz
        """

    rule CreateNormalDBForPureCN:
        input: 
            normal_coverage=expand(config["dir"]["base"]+"/{sample}/Normal/PureCN/{seq_name}.sort.RG.dedup.recall_coverage_loess.txt.gz",zip,sample=samples["samples"][samples["type"]=="Normal"],seq_name=SAMPLES_NORMAL),
            ref=config["genome"]["fasta_file"],
            target=config["metadata"]["design"],
            normal_vcf=config["dir"]["base"]+"/normals.vcf.gz"
        output:
            config["dir"]["base"]+'/normal_db_pureCN/'+'mapping_bias_'+config["metadata"]["design_name"] + "_" + config["genome"]["version"]+".rds",
            config["dir"]["base"]+'/normal_db_pureCN/'+'normalDB_'+config["metadata"]["design_name"] + "_" + config["genome"]["version"]+".rds"
        container:
            "docker://ngsom/bioconductor"
        params:
             base_dir=output_dir,
             normal_coverage_input=lambda wc, input: "".join(['%s\n' % x for x in input.normal_coverage]),
             assay_name=config["metadata"]["design_name"],
             genome_version=config["genome"]["version"]
        shell:"""
            echo "{params.normal_coverage_input}" > {params.base_dir}/normal_coverage.list
            Rscript /usr/local/lib/R/site-library/PureCN/extdata/NormalDB.R \
            --out-dir {params.base_dir}/normal_db_pureCN \
            --coverage-files {params.base_dir}/normal_coverage.list \
            --normal-panel {input.normal_vcf} \
            --genome {params.genome_version} \
            --assay {params.assay_name}
        """ 

rule PureCN :
    input:
        interval=config["dir"]["base"]+"/baits_interval.txt",
        vcf_tumor=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Mutect2/{seq_name}_vs_{normal}.Mutect2.somatic.filtered.vcf",
        paired=get_paired_coverage_loess,
        normal_db=config["PureCN"]["normal_db"] if not create_normal_db else config["dir"]["base"]+'/normal_db_pureCN/'+'normalDB_'+config["metadata"]["design_name"] + "_" + config["genome"]["version"]+".rds",
        mapping_bias=config["PureCN"]["mapping_bias"] if not create_normal_db else config["dir"]["base"]+'/normal_db_pureCN/'+'mapping_bias_'+config["metadata"]["design_name"] + "_" + config["genome"]["version"]+".rds"
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/PureCN/{seq_name}_vs_{normal}_dnacopy.seg"
    container:
        "docker://ngsom/bioconductor"
    params:
        base_dir=output_dir,
        genome_version=config["genome"]["version"]
    shell:"""
    Rscript /usr/local/lib/R/site-library/PureCN/extdata/PureCN.R \
    --out {params.base_dir}/{wildcards.sample}/SomaticAnalysis/PureCN \
    --tumor {input.paired[0]} \
    --sampleid {wildcards.seq_name}_vs_{wildcards.normal} \
    --vcf {input.vcf_tumor} \
    --fun-segmentation PSCBS \
    --normaldb {input.normal_db} \
    --mapping-bias-file {input.mapping_bias} \
    --intervals {input.interval} \
    --genome {params.genome_version} \
    --model betabin \
    --force --post-optimize --seed 123
    """

#Copy number with Varscan2
rule VarScan2CopyNumber :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
        gc=config["genome"]["gc_file"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/VarScan2CN/{seq_name}_vs_{normal}.copynumber.called"
    container:
        "docker://ngsom/somatic"
    params:
        base_dir=output_dir,
    shell:"""
    cd {params.base_dir}/{wildcards.sample}/SomaticAnalysis/VarScan2CN/
    samtools mpileup -q 1 -f {input.ref} {input.paired[1]} {input.paired[0]} | java -Xmx16G -jar /usr/share/java/VarScan.v2.3.9.jar copynumber varScan --mpileup 1
    java -Xmx16G -jar /usr/share/java/VarScan.v2.3.9.jar copyCaller output.copynumber --output-file {output}
    """

#Run delly somatic
rule iCallSV :
    input:
        paired=get_paired_samples,
        ref=config["genome"]["fasta_file"],
        region_to_exclude = config["iAnnotSV"]["region_to_exclude"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}_allSVFiltered_functional.txt",
    container:
        "docker://srikarchamala/icallsv:1.2"
    params:
        base_dir=output_dir
    shell:
        """
        mkdir -p {params.base_dir}/{wildcards.sample}/SomaticAnalysis/iCallSV/{wildcards.seq_name}
        python /usr/local/icallsv/0.0.6/bin/iCallSV.py -sc /shared/home/aguille/iCallSV_config.ini -abam {input.paired[0]} -bbam {input.paired[1]} -aId {wildcards.seq_name} -bId {wildcards.normal} -o {params.base_dir}/{wildcards.sample}/SomaticAnalysis/iCallSV/{wildcards.seq_name} -op {wildcards.seq_name}
        cp {params.base_dir}/{wildcards.sample}/SomaticAnalysis/iCallSV/{wildcards.seq_name}/StructuralVariantAnalysis/DellyDir/{wildcards.seq_name}/{wildcards.seq_name}_allSVFiltered_functional.txt {output}
        """

#Delly VCF to tab
rule vcf2tab :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Delly/{seq_name}_vs_{normal}.Delly.somatic.sv.vcf",
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Delly/{seq_name}_vs_{normal}.Delly.somatic.sv.tab",
    conda:
        env_file_sv
    params:
        base_dir=output_dir
    shell:"""
        dellyVcf2TabScript.py {input.vcf} {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Delly/
        awk 'BEGIN{{OFS="\t"}} NR>1{{ gsub("chr","",$FN) }}{{print $FN}}' {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Delly/{wildcards.seq_name}_vs_{wildcards.normal}.Delly.somatic.sv.tab > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Delly/{wildcards.seq_name}_vs_{wildcards.normal}.Delly.somatic.sv.tab.tmp
        mv {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Delly/{wildcards.seq_name}_vs_{wildcards.normal}.Delly.somatic.sv.tab.tmp {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Delly/{wildcards.seq_name}_vs_{wildcards.normal}.Delly.somatic.sv.tab
        """

#Filter Delly VCF
rule filterDellyCalls :
    input:
        vcf=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Delly/{seq_name}_vs_{normal}.Delly.somatic.sv.vcf",
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Delly/{seq_name}_vs_{normal}.Delly.somatic.sv.stats",
    conda:
        env_file_sv
    params:
        base_dir=output_dir
    shell:"""
        FilterDellyCalls.py -p 1 -f Delly {input.vcf} {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Delly/{wildcards.seq_name}_vs_{wildcards.normal}.Delly.somatic.sv
        """

#Annot Delly SV
rule iAnnotSV :
    input:
        tab=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Delly/{seq_name}_vs_{normal}.Delly.somatic.sv.tab",
        ref_file=config["iAnnotSV"]["ref_file"],
        canonical_txt=config["iAnnotSV"]["canonical_txt"],
        uniprot=config["iAnnotSV"]["uniprot"],
        repeat_region=config["iAnnotSV"]["repeat_region"],
        dgv=config["iAnnotSV"]["dgv"],
        cancer_census=config["iAnnotSV"]["cancer_census"],
        cosmic_fusion_count=config["iAnnotSV"]["cosmic_fusion_count"],
        all_txt=config["iAnnotSV"]["all_canonical_txt"]
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/Delly/{seq_name}_vs_{normal}.Delly_Annotated.txt",
    conda:
        env_file_sv
    params:
        base_dir=output_dir
    shell:
        """
        iAnnotateSV.py \
        -i {input.tab} \
        -ofp {wildcards.seq_name}_vs_{wildcards.normal}.Delly \
        -o {params.base_dir}/{wildcards.sample}/SomaticAnalysis/Delly \
        -r hg19 \
        -rf {input.ref_file} \
        -c {input.canonical_txt} \
        -u {input.uniprot} \
        -rr {input.repeat_region} \
        -dgv {input.dgv} \
        -cc {input.cancer_census} \
        -cct {input.cosmic_fusion_count} \
        --canonicalTranscripts {input.all_txt} \
        -d 3000
        """

#Merge Delly Annot and stat
rule MergeDellyAnnotAndStat :
    input:
        annot=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Delly/{seq_name}_vs_{normal}.Delly_Annotated.txt",
        stat=config["dir"]["base"]+"/{sample}/SomaticAnalysis/Delly/{seq_name}_vs_{normal}.Delly.somatic.sv.stats",
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.Delly.somatic.sv.result",
    conda:
        env_file_sv
    params:
        base_dir=output_dir
    shell:"""
        paste {input.stat} {input.annot} > {output}
        """

#Somatic annotation
rule SomaticAnnotation:
    input:
        snp_vcf=output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.snv.merge.filtered.vcf",
        snp_stats=output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.snv.merge.stats",
        indel_vcf=output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.indel.merge.filtered.vcf",
        indel_stats=output_dir+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.indel.merge.stats",
    output:
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.snv.result",
        config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.somatic.indel.result"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_name}_{normal}.Annovar.txt"
    params:
        base_dir=output_dir,
        annovar_db=annovar_db,
        base_used_somatic=base_used_somatic,
        genome_version=config["genome"]["version"]
    shell:"""
    #SNV Annot
    convert2annovar.pl {input.snp_vcf} -format vcf4old -includeinfo --outfile {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.snv.txt ;
	table_annovar.pl {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.snv.txt {params.annovar_db} -buildver {params.genome_version} -remove -thread 8 -protocol {params.base_used_somatic} -operation g,f,f,f,f,f,f,f,f,f,f -polish ;
	paste {input.snp_stats} {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.snv.txt.{params.genome_version}_multianno.txt > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.snv.result ;
    #INDEL Annot
    convert2annovar.pl {input.indel_vcf} -format vcf4old -includeinfo --outfile {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.indel.txt ;
    table_annovar.pl {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.indel.txt {params.annovar_db} -buildver {params.genome_version} -remove -thread 8 -protocol {params.base_used_somatic} -operation g,f,f,f,f,f,f,f,f,f,f -polish ;
    paste {input.indel_stats} {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.indel.txt.{params.genome_version}_multianno.txt > {params.base_dir}/{wildcards.sample}/SomaticAnalysis/{wildcards.seq_name}_vs_{wildcards.normal}.somatic.indel.result ;
    """

#Germline Annotation
rule GermlineAnnotation:
    input:
        snv_vcf=output_dir+"/{sample}/Normal/{seq_name}.germline.snv.merge.filtered.vcf",
        snv_stats=output_dir+"/{sample}/Normal/{seq_name}.germline.snv.merge.stats",
        indel_vcf=output_dir+"/{sample}/Normal/{seq_name}.germline.indel.merge.filtered.vcf",
        indel_stats=output_dir+"/{sample}/Normal/{seq_name}.germline.indel.merge.stats",
    output:
        config["dir"]["base"]+"/{sample}/Normal/{seq_name}.germline.snv.result",
        config["dir"]["base"]+"/{sample}/Normal/{seq_name}.germline.indel.result"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_name}.AnnovarGermline.txt"
    params:
        base_dir=output_dir,
        annovar_db=annovar_db,
        base_used_germline=base_used_germline,
        genome_version=config["genome"]["version"]
    shell:"""
    #SNV Annot
    convert2annovar.pl {input.snv_vcf} -format vcf4old -includeinfo --outfile {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.snv.txt ;
	table_annovar.pl {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.snv.txt {params.annovar_db} -buildver {params.genome_version} -remove -thread 8 -protocol {params.base_used_germline} -operation g,f,f,f,f,f,f,f,f,f,f,f,f -polish ;
	paste {input.snv_stats} {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.snv.txt.{params.genome_version}_multianno.txt > {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.snv.result ;
    #INDEL Annot
    convert2annovar.pl {input.indel_vcf} -format vcf4old -includeinfo --outfile {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.indel.txt ;
	table_annovar.pl {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.indel.txt {params.annovar_db} -buildver {params.genome_version} -remove -thread 8 -protocol {params.base_used_germline} -operation g,f,f,f,f,f,f,f,f,f,f,f,f -polish ;
	paste {input.indel_stats} {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.indel.txt.{params.genome_version}_multianno.txt > {params.base_dir}/{wildcards.sample}/Normal/{wildcards.seq_name}.germline.indel.result ;
    """

rule BedToInterval:
    input:
        ref_dict=config["genome"]["dict_file"],
        target=config["metadata"]["design"],
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam"
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/target.interval"
    params:
        base_dir=output_dir
    container:
        "docker://ngsom/tumorseq"
    shell:
        """
        java -Xmx16G -jar /usr/share/java/picard.jar BedToIntervalList \
        -I {input.target} \
        -O {output} \
        -SD {input.ref_dict}
        """

rule HsMetrics:
    input:
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/target.interval"
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.Hsmetrics"
    params:
        base_dir=output_dir
    container:
        "docker://ngsom/tumorseq"
    "benchmarks/{sample}_{seq_type}_{seq_name}.HsMetrics.txt"
    shell:
        """
        java -Xmx16G -jar /usr/share/java/picard.jar CollectHsMetrics \
        -I {input.bam} \
        -O {output} \
        -BAIT_INTERVALS {input.target} \
        -TARGET_INTERVALS {input.target}
        """

#Run qualimap (QC)
rule qualimap:
    input:
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        ref=config["genome"]["fasta_file"],
        target=config["metadata"]["design"],
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/qualimapReport.html",
        directory(config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/raw_data_qualimapReport")
    params:
        base_dir=output_dir
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.qualimap.txt"
    shell:
        """
        awk '{{print $1"\t"$2"\t"$3"\t"$4"\t.\t." }}' {input.target} > {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/{wildcards.seq_name}.target.bed
        export _JAVA_OPTIONS="-Djava.awt.headless=true"
        qualimap bamqc -ip -nt 12 -bam {input.bam} --java-mem-size=64G -outdir {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/report_{wildcards.seq_name} -gff {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/{wildcards.seq_name}.target.bed
        rm {params.base_dir}/{wildcards.sample}/{wildcards.seq_type}/{wildcards.seq_name}.target.bed
        """

rule CoverageUniformity :
    input:
        index=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam.bai",
        bam=config["dir"]["base"]+"/{sample}/{seq_type}/{seq_name}"+tag_process_mb+"sort"+tag_process_uniq+"RG"+tag_process_dedup+"recall."+"bam",
        target=config["metadata"]["design"],
        chrLength=config["genome"]["chrLength_file"],
    output:
        cov=temp(config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.cov"),
        uniformity=config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.cov.uniformity"
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/{sample}_{seq_type}_{seq_name}.CoverageUniformity.txt"
    params:
        base_dir=output_dir
    shell:
        """
		bedtools coverage -sorted -d -g {input.chrLength} -a {input.target} -b {input.bam} > {output.cov}
		source activate utils2
	    workflow/scripts/coverage_uniformity2.py {output.cov} {output.uniformity}
        """

rule collect_metrics :
    input:
        qualimap_report=config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/qualimapReport.html",
        cov_uni=config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.cov.uniformity",
        adapt_bias=config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.pre_adapter_summary_metrics.txt",
        bait_bias=config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.bait_bias_summary_metrics.txt",
        error=config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.error_summary_metrics.txt" ,
        fastqc = fastqc_output,
        hsmetrics = config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.Hsmetrics"
    output:
        config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.bam.qc"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:
        """
        source activate utils
        workflow/scripts/collect_metrics2.py {input.qualimap_report} {input.cov_uni} {input.bait_bias} {input.adapt_bias} {input.error} {input.fastqc} {output}
        """

#Merge snv somatic results from different samples
rule mergeSomaticSNVResult :
    input:
        input_merge_snv
    output:
        config["dir"]["base"]+"/somatic.snv.filtered.txt",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/mergeSomaticSNVResult.txt"
    params:
        base_dir=output_dir
    shell:
        """
        head -q -n 1 {input} | head -q -n 1 > {params.base_dir}/somatic.snv.txt || error_exit 'head failed'
        tail -q -n +2 {input} >> {params.base_dir}/somatic.snv.txt || error_exit 'tail failed'
        awk 'BEGIN{{OFS="\t"}} NR==1 ;NR > 1 {{print $0 | "sort -k3d,3d -k4n,4n -k2d,2d" }}' {params.base_dir}/somatic.snv.txt > {params.base_dir}/somatic.snv.sort.txt || error_exit 'awk failed'
        source activate utils
        workflow/scripts/prioritize_variants.py -m snp {params.base_dir}/somatic.snv.sort.txt {params.base_dir}/somatic.snv.prio.txt || error_exit 'prioritize failed'
        awk 'BEGIN{{OFS="\t"}} NR==1{{print $0,"STATUT"}} NR>1{{print $0,"SOMATIC"}}' {params.base_dir}/somatic.snv.prio.txt > {output} || error_exit 'awk3 failed'
        rm {params.base_dir}/somatic.snv.txt || error_exit 'rm failed'
        rm {params.base_dir}/somatic.snv.sort.txt || error_exit 'rm failed'
        rm {params.base_dir}/somatic.snv.prio.txt || error_exit 'rm failed'
        """

#Merge indel somatic results from different samples
rule mergeSomaticINDELResult :
    input:
        input_merge_indel
    output:
        config["dir"]["base"]+"/somatic.indel.filtered.txt",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/mergeSomaticINDELResult.txt"
    params:
        base_dir=output_dir
    shell:
        """
        head -q -n 1 {input} | head -q -n 1 > {params.base_dir}/somatic.indel.txt || error_exit 'head failed'
        tail -q -n +2 {input} >> {params.base_dir}/somatic.indel.txt || error_exit 'tail failed'
        awk 'BEGIN{{OFS="\t"}} NR==1 ; NR > 1 {{print $0 | "sort -k3d,3d -k4n,4n -k2d,2d" }}' {params.base_dir}/somatic.indel.txt > {params.base_dir}/somatic.indel.sort.txt || error_exit 'awk failed'
        source activate utils
        workflow/scripts/prioritize_variants.py -m indel {params.base_dir}/somatic.indel.sort.txt {params.base_dir}/somatic.indel.prio.txt || error_exit 'prioritize failed'
        awk 'BEGIN{{OFS="\t"}} NR==1{{print $0,"STATUT"}} NR>1{{print $0,"SOMATIC"}}' {params.base_dir}/somatic.indel.prio.txt > {output} || error_exit 'awk3 failed'
        rm {params.base_dir}/somatic.indel.txt || error_exit 'rm failed'
        rm {params.base_dir}/somatic.indel.sort.txt || error_exit 'rm failed'
        rm {params.base_dir}/somatic.indel.prio.txt || error_exit 'rm failed'
        """

#Merge Indel SV result
rule mergeSVResultFiles :
    input:
        expand(config["dir"]["base"]+"/{sample}/SomaticAnalysis/{seq_name}_vs_{normal}.Delly.somatic.sv.result",zip,tumor=TUMOR, normal=NORMAL, seq_name=SAMPLES_TUMOR)
    output:
        config["dir"]["base"]+"/somatic.sv.filtered.txt",
    container:
        "docker://ngsom/tumorseq"
    shell:
        """
        cat {input} > {output}
        """

#Merge snv germline results from different samples
rule mergeGermlineSNVResult :
    input:
        expand(config["dir"]["base"]+"/{sample}/Normal/{seq_name}.germline.snv.result",zip,sample=samples["samples"][samples["type"]=="Normal"],seq_name=SAMPLES_NORMAL)
    output:
        config["dir"]["base"]+"/germline.snv.filtered.txt",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/mergeGermlineSNVResult.txt"
    params:
        base_dir=output_dir
    shell:
        """
        head -q -n 1 {input} | head -q -n 1 > {params.base_dir}/germline.snv.txt || error_exit 'head failed'
        tail -q -n +2 {input} >> {params.base_dir}/germline.snv.txt || error_exit 'tail failed'
        awk 'BEGIN{{OFS="\t"}} NR==1 ; NR > 1 {{print $0 | "sort -k3d,3d -k4n,4n -k2d,2d" }}' {params.base_dir}/germline.snv.txt > {params.base_dir}/germline.snv.sort.txt || error_exit 'awk failed'
        source activate utils
        workflow/scripts/prioritize_variants.py -m snp {params.base_dir}/germline.snv.sort.txt {params.base_dir}/germline.snv.prio.txt || error_exit 'prioritize failed'
        awk 'BEGIN{{OFS="\t"}} NR==1{{print $0,"STATUT"}} NR>1{{print $0,"GERMLINE"}}' {params.base_dir}/germline.snv.prio.txt > {output} || error_exit 'awk2 failed'
        rm {params.base_dir}/germline.snv.txt || error_exit 'rm failed'
        rm {params.base_dir}/germline.snv.sort.txt || error_exit 'rm failed'
        rm {params.base_dir}/germline.snv.prio.txt || error_exit 'rm failed'
        """

#Merge indel germline results from different samples
rule mergeGermlineINDELResult :
    input:
        expand(config["dir"]["base"]+"/{sample}/Normal/{seq_name}.germline.indel.result",zip,sample=samples["samples"][samples["type"]=="Normal"],seq_name=SAMPLES_NORMAL)
    output:
        config["dir"]["base"]+"/germline.indel.filtered.txt",
    container:
        "docker://ngsom/tumorseq"
    benchmark:
        "benchmarks/mergeGermlineINDELResult.txt"
    params:
        base_dir=output_dir
    shell:
        """
        head -q -n 1 {input} | head -q -n 1 > {params.base_dir}/germline.indel.txt || error_exit 'head failed'
        tail -q -n +2 {input} >> {params.base_dir}/germline.indel.txt || error_exit 'tail failed'
        awk 'BEGIN{{OFS="\t"}} NR==1 ; NR > 1 {{print $0 | "sort -k3d,3d -k4n,4n -k2d,2d" }}' {params.base_dir}/germline.indel.txt > {params.base_dir}/germline.indel.sort.txt || error_exit 'awk failed'
        source activate utils
        workflow/scripts/prioritize_variants.py -m indel {params.base_dir}/germline.indel.sort.txt {params.base_dir}/germline.indel.prio.txt || error_exit 'prioritize failed'
        awk 'BEGIN{{OFS="\t"}} NR==1{{print $0,"STATUT"}} NR>1{{print $0,"GERMLINE"}}' {params.base_dir}/germline.indel.prio.txt > {output} || error_exit 'awk2 failed'
        rm {params.base_dir}/germline.indel.txt || error_exit 'rm failed'
        rm {params.base_dir}/germline.indel.sort.txt || error_exit 'rm failed'
        rm {params.base_dir}/germline.indel.prio.txt || error_exit 'rm failed'
        """

#Merge QC result
rule multiQC :
    input:
        qualimap=expand(config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/raw_data_qualimapReport",zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST),
        hs_metrics=expand(config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.Hsmetrics",zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST),
        fastqc_zip=fastqc_output_zip
    output:
        config["dir"]["base"]+output_analysis+"/multiqc_report.html"
    container:
        "docker://ewels/multiqc"
    params:
        base_dir=output_dir,
        out=output_dir+output_analysis
    shell:
        """
        multiqc -c /shared/projects/pmngs/projet_seq/projet_WES_BIDIFLY/multiqc_config.yaml {input.qualimap} {input.hs_metrics} {input.fastqc_zip} --outdir {params.out} --quiet
        """

#Merge QC result
rule mergeQC :
    input:
        expand(config["dir"]["base"]+"/{sample}/{seq_type}/report_{seq_name}/{seq_name}.bam.qc",zip,sample=samples["samples"],seq_type=samples["type"],seq_name=SEQ_LIST)
    output:
        config["dir"]["base"]+output_analysis+"/bam.stats"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:
        """
        cat {input} > {output} || error_exit 'mergeQC failed'
        """

#Merge MSIsensor result
rule mergeMSI :
    input:
        input_merge_msi
    output:
        config["dir"]["base"]+output_analysis+"/merge.msi"
    container:
        "docker://ngsom/tumorseq"
    params:
        base_dir=output_dir
    shell:
        """
        head -q -n 1 {input} | head -q -n 1 > {output} || error_exit 'head failed'
        tail -q -n +2 {input} >> {output} || error_exit 'tail failed'
        """

#Get import files, ready to be load in oncodb web app
rule getImportFiles :
    input:
        somatic_snv=config["dir"]["base"]+"/somatic.snv.filtered.txt",
        somatic_indel=config["dir"]["base"]+"/somatic.indel.filtered.txt",
        germline_snv=config["dir"]["base"]+"/germline.snv.filtered.txt",
        germline_indel=config["dir"]["base"]+"/germline.indel.filtered.txt",
    output:
        config["dir"]["base"]+output_analysis+"/somatic.snv.import.csv",
        config["dir"]["base"]+output_analysis+"/somatic.indel.import.csv",
        config["dir"]["base"]+output_analysis+"/germline.snv.import.csv",
        config["dir"]["base"]+output_analysis+"/germline.indel.import.csv",
    params:
        base_dir=output_dir+output_analysis
    run:
        somatic_couple=expand("{seq_name}_vs_{normal}",zip, normal=NORMAL,seq_name=SAMPLES_TUMOR)
        regexp_somatic = "|".join(somatic_couple)
        regexp_somatic = regexp_somatic + "|SAMPLE"
        regexp_normal = "|".join(NORMAL)
        regexp_normal = regexp_normal + "|SAMPLE"
        shell("""
        awk 'BEGIN{{FS="\t";OFS="\t"}} $2 ~ /%s/ {{print $FN}}' {input.somatic_snv} >  {params.base_dir}/somatic.snv.import.csv;
        awk 'BEGIN{{FS="\t";OFS="\t"}} $2 ~ /%s/ {{print $FN}}' {input.somatic_indel} >  {params.base_dir}/somatic.indel.import.csv;
        awk 'BEGIN{{FS="\t";OFS="\t"}} $2 ~ /%s/ {{print $FN}}' {input.germline_snv} >  {params.base_dir}/germline.snv.import.csv;
        awk 'BEGIN{{FS="\t";OFS="\t"}} $2 ~ /%s/ {{print $FN}}' {input.germline_indel} >  {params.base_dir}/germline.indel.import.csv;
        """%(regexp_somatic,regexp_somatic,regexp_normal,regexp_normal))
